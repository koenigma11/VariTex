{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VariTex Demo\n",
    "This notebook is about [Varitex: Variational Neural Face Textures](https://arxiv.org/pdf/2104.05988.pdf) ([ICCV 2021](https://iccv2021.thecvf.com/)). For more information, please visit the [project page](https://mcbuehler.github.io/VariTex/).\n",
    "\n",
    "![](https://ait.ethz.ch/people/buehler/public/varitex/teaser.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Please follow the instructions in the [README](https://github.com/mcbuehler/VariTex/blob/main/README.md) and download the following files:\n",
    "- [ ] the model [checkpoint](https://ait.ethz.ch/people/buehler/public/varitex/pretrained.zip)\n",
    "- [ ] the preprocessed [dataset](https://ait.ethz.ch/people/buehler/public/varitex/dataset_preprocessed.zip)\n",
    "- [ ] the [Basel Face Model](https://faces.dmi.unibas.ch/bfm/bfm2017.html)\n",
    "- [ ] the Basel Face Model [UV parameterization](https://github.com/unibas-gravis/parametric-face-image-generator/blob/master/data/regions/face12.json). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "Global seed set to 1234\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "from varitex.data.keys_enum import DataItemKey as DIK\n",
    "pl.seed_everything(1234)\n",
    "from mutil.object_dict import ObjectDict\n",
    "from torch.nn.functional import normalize as normalizeT\n",
    "from runValidation import getModel, getOpt\n",
    "from varitex import validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/matthias/ETH/Thesis/nFlows/nflows')\n",
    "#### Nflows\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.flows.realnvp import SimpleRealNVP\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.coupling import CouplingTransform, AffineCouplingTransform, AdditiveCouplingTransform\n",
    "from nflows.flows import realnvp\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/matthias/ETH/Thesis/nFlows/pytorch-normalizing-flows/')\n",
    "\n",
    "#### NfLib\n",
    "# from nflib.flows import (\n",
    "#     AffineConstantFlow, ActNorm, AffineHalfFlow, \n",
    "#     SlowMAF, MAF, IAF, Invertible1x1Conv,\n",
    "#     NormalizingFlow, NormalizingFlowModel,\n",
    "# )\n",
    "# from nflib.spline_flows import NSF_AR, NSF_CL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch import distributions\n",
    "from torch.distributions import MultivariateNormal, Uniform, TransformedDistribution, SigmoidTransform\n",
    "import itertools\n",
    "\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.flows.realnvp import SimpleRealNVP\n",
    "from nflows.flows.autoregressive import MaskedAutoregressiveFlow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform, MaskedUMNNAutoregressiveTransform, MaskedPiecewiseLinearAutoregressiveTransform,MaskedPiecewiseQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation, RandomPermutation\n",
    "from nflows.transforms.nonlinearities import LeakyReLU\n",
    "from nflows.transforms.normalization import ActNorm, BatchNorm\n",
    "from nflows.transforms.coupling import CouplingTransform, AffineCouplingTransform, AdditiveCouplingTransform\n",
    "from nflows.transforms.standard import PointwiseAffineTransform\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BFM 2017 into GPU... (this can take a while)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "Res128_nonorm_path = '/home/matthias/ETH/Thesis/VariTexLocal/VariTex/output/varitex/varitex/Res128_GLO_nonorm/checkpoints/epoch=43-step=377079.ckpt'\n",
    "\n",
    "ckptFolder ='/home/matthias/ETH/Thesis/VariTexLocal/output/ckpts/Res128_GLO_NoNorm'\n",
    "filename = 'epoch=43-step=377079.ckpt'\n",
    "Res128_nonorm_path = os.path.join(ckptFolder, filename)\n",
    "Res128_norm1_path = '/home/matthias/ETH/Thesis/VariTexLocal/output/forDemo/1vc1xbec/checkpoints/epoch=43-step=377079.ckpt'\n",
    "nfFolderPath = '/home/matthias/ETH/Thesis/nFlows/nflows'\n",
    "nfCKPT = 'young-sun-6.ckpt'\n",
    "nfPath = os.path.join(nfFolderPath,nfCKPT)\n",
    "opt = {\n",
    "\n",
    "        #\"checkpoint\": os.path.join(os.getenv(\"CP\", \"pretrained/ep44.ckpt\")),\n",
    "        \"checkpoint\": Res128_nonorm_path,\n",
    "        \"dataroot_npy\": os.path.join(os.getenv(\"DP\", \"\"), 'FFHQ/preprocessed_dataset_new'),\n",
    "        \"path_bfm\": os.path.join(os.getenv(\"FP\", \"\"), \"basel_facemodel/model2017-1_face12_nomouth.h5\"),\n",
    "        \"path_uv\": os.path.join(os.getenv(\"FP\", \"\"), \"basel_facemodel/face12.json\"),\n",
    "        \"device\": \"cuda\"\n",
    "        }\n",
    "\n",
    "path_latent = os.path.join(os.getenv(\"DP\"), \"FFHQ/preprocessed_dataset_new/latents.npy\")\n",
    "\n",
    "from varitex.demo import Demo\n",
    "opt.update(use_NF=False)\n",
    "demo = Demo(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Latent Distributions\n",
    "The variables `latent_mean` and `latent_std` contain the mean and standard deviations of all samples from the holdout set, predicted by the encoder. You can choose the index of the distribution that you want to render, or you can sample from these distributions.\n",
    "\n",
    "\n",
    "Example indices from the holdout set used the [paper](https://arxiv.org/pdf/2104.05988.pdf):\n",
    "* [Teaser image](https://ait.ethz.ch/people/buehler/public/varitex/teaser.png) (Fig. 1): 184 (female), 33 (male).\n",
    "* Fig. 3: 8 (Identity 1), 904 (identity 2).\n",
    "* Fig. 5: Sampled from distributions 184, 148, 313, 319."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "latent_distributions = np.load(path_latent)\n",
    "latent_mean = torch.Tensor(latent_distributions[:,0])\n",
    "latent_std = torch.Tensor(latent_distributions[:,1])\n",
    "print(\"{} distributions loaded.\".format(latent_mean.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VariTex Controls\n",
    "\n",
    "![](https://ait.ethz.ch/people/buehler/public/varitex/varitex_pipeline_inference.png)\n",
    "\n",
    "The generator $G$ provides\n",
    "    a) __neural control__ over identity and appearance via a latent code `z` (consisting of two parts $z_{face}$ and $z_{additive}$) and \n",
    "    b) __graphical control__ over geometry (shape `sp`, expression `ep`, and pose `R`) via the parameters of a 3D morphable face model. For simplicity, let's define the pose as euler angles `theta` ($\\theta$).\n",
    "    \n",
    "$$G (z, sp, ep, R(\\theta))$$\n",
    "\n",
    "* `z` $\\in \\mathbb{R}^{256}$: Latent identity code.\n",
    "* `sp` $\\in \\mathbb{R}^{199}$ and `ep` $\\in \\mathbb{R}^{100}$: Shape and expression coefficients of the Basel Face Model. They define the geometry of the rendered face. Zeros yield a neutral face.\n",
    "* `theta` $\\in \\mathbb{R}^3$: Pose in euler angles (degrees). Zeros yield a frontal face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical Control: Pose and Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape and Expression\n",
    "We load shape `sp` and expression `ep` coefficients from the FFHQ validation set. Choose any other index to load different shapes and expressions from the validation set. These parameters could also be sampled from the Basel Face Model.\n",
    "\n",
    "Change the indices for `sp` and `ep` to modify the facial expression, and shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcapath = '/home/matthias/ETH/Thesis/VariTexLocal/datasets/pcaLatents.npy'\n",
    "pca = np.load(pcapath).astype('float')\n",
    "pcaN = (pca[:,:128])\n",
    "print(np.linalg.norm(pcaN,axis=1))\n",
    "usedpca = pcaN/np.linalg.norm(pcaN,axis=1).reshape((-1,1))\n",
    "print(np.linalg.norm(usedpca,axis=1))\n",
    "print(usedpca.shape)\n",
    "mean = usedpca.mean(1).mean(0)\n",
    "std = usedpca.std(1).mean(0)\n",
    "normalDist = np.random.normal(mean, std, (70000,128))\n",
    "print(usedpca.std(1).mean(0)*100000.)\n",
    "print(normalDist.std(1).mean(0)*100000.)\n",
    "plt.hist([normalDist.flatten(),usedpca.flatten()],bins = 100,label=['G','x'], histtype='stepfilled')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.hist(stdNormal,bins = 100,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = torch.randn(100000).numpy().flatten()\n",
    "mu=1.\n",
    "sigma=1.0\n",
    "normal = torch.normal(mu,sigma,size = [100000]).numpy().flatten()\n",
    "plt.hist([standard, normal],bins = 100,color=['r','b'], histtype='stepfilled')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapes, expressions = demo.load_shape_expressions()\n",
    "index_id, index_sp, index_ep = 184, 184, 184\n",
    "sp = shapes[index_sp].unsqueeze(0)\n",
    "ep = expressions[index_ep].unsqueeze(0)\n",
    "theta = torch.Tensor((0,-35,0))\n",
    "z_sampled = (normalizeT(torch.randn(10, 256),dim=1)*1)\n",
    "\n",
    "\n",
    "norm = 0\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0)*norm, sp=sp, ep=ep, theta=theta) for z in z_sampled]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spherical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0)*norm, sp=sp, ep=ep, theta=theta) for z in z_sampled]\n",
    "print(torch.linalg.norm(z_sampled, dim=1))\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 2\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0)*norm, sp=sp, ep=ep, theta=theta) for z in z_sampled]\n",
    "print(torch.linalg.norm(z_sampled*norm, dim=1))\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 3\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0)*norm, sp=sp, ep=ep, theta=theta) for z in z_sampled]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 4\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0)*norm, sp=sp, ep=ep, theta=theta) for z in z_sampled]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 5\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0)*norm, sp=sp, ep=ep, theta=theta) for z in z_sampled]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 6\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0)*6, sp=sp, ep=ep, theta=theta) for z in z_sampled]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutil.np_util import interpolation\n",
    "n_samples = 10\n",
    "\n",
    "norm = 3\n",
    "zA, zB = (normalizeT(torch.randn(256),dim=0)*norm), (normalizeT(torch.randn(256),dim=0)*norm) \n",
    "z_interpolated = torch.Tensor(interpolation(n_samples, zA.numpy(), zB.numpy()))\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in z_interpolated]\n",
    "print(\"Norms: \", torch.linalg.norm(z_interpolated, dim=1))\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_out = [demo.runGlo(z=normalizeT(z, dim=0).unsqueeze(0)*norm, sp=sp, ep=ep, theta=theta) for z in z_interpolated]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero to norm n interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "norm = 11\n",
    "zA, zB = (torch.zeros(256).unsqueeze(0)), (normalizeT(torch.randn(256),dim=0).unsqueeze(0)*norm) \n",
    "z_interpolated = torch.Tensor(interpolation(n_samples, zA.numpy(), zB.numpy()))\n",
    "batches_out = [demo.runGlo(z=z, sp=sp, ep=ep, theta=theta) for z in z_interpolated]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = demo.pipeline.Z.weight\n",
    "latent = latent[:59990]\n",
    "latent_training_codes = latent[21:31]\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in latent_training_codes]\n",
    "print(\"Norms: \", torch.linalg.norm(latent_training_codes,dim=1))\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_training_codes = normalizeT(latent_training_codes, dim=1)*2.5\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in latent_training_codes]\n",
    "print(\"Norms: \", torch.linalg.norm(latent_training_codes,dim=1))\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_hist_full(i):\n",
    "    HIST_BINS = np.linspace(-1.5, 1.5, 100)\n",
    "    plt.hist(latent.detach().cpu().numpy().flatten(), HIST_BINS,alpha=1)\n",
    "    filename = os.path.join('output/hists/full','hist_full_epoch')\n",
    "    #plt.savefig(filename+str(i)+'full.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "def show_hist(i):\n",
    "    HIST_BINS = np.linspace(-1.5, 1.5, 100)\n",
    "    plt.hist(latent[i,:128].detach().cpu().numpy().flatten(), HIST_BINS,alpha=1)\n",
    "    plt.hist(latent[i,128:].detach().cpu().numpy(), HIST_BINS,alpha=0.6)\n",
    "    plt.title('Latent code: '+str(i))\n",
    "    filename = os.path.join('output/hists','hist_epoch')\n",
    "    plt.savefig(filename+str(i)+'.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.mean(latent,dim=1).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = torch.load(Res128_nonorm_path)['state_dict']['Z.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Flows (extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NflowLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = demo.pipeline.Z.weight\n",
    "latent = latent[:59990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransform(transform, config):\n",
    "    ##Permutations\n",
    "    if(transform == 'randomPermutation'):\n",
    "        return RandomPermutation(features=config['num_features'])\n",
    "    elif(transform == 'reversePermutation'):\n",
    "        return ReversePermutation(features=config['num_features'])\n",
    "    ##Autoregressions\n",
    "    elif(transform == 'maskedAffineAR'):\n",
    "        return MaskedAffineAutoregressiveTransform(features=config['num_features'],\n",
    "                                                   hidden_features=config['hidden_features'])\n",
    "    elif(transform == 'maskedAffineARUMNN'):\n",
    "        return MaskedUMNNAutoregressiveTransform(features=config['num_features'],\n",
    "                                                 hidden_features=config['hidden_features'])\n",
    "    elif(transform == 'maskedAffineARLinear'):\n",
    "        return MaskedPiecewiseLinearAutoregressiveTransform(features=config['num_features'],\n",
    "                                                         hidden_features=config['hidden_features'],\n",
    "                                                        num_bins = 10)\n",
    "    elif(transform == 'maskedAffineARQuadratic'):\n",
    "        return MaskedPiecewiseQuadraticAutoregressiveTransform(features=config['num_features'],\n",
    "                                                        hidden_features=config['hidden_features'],\n",
    "                                                        num_bins = 10)\n",
    "    elif(transform == 'actNorm'):\n",
    "        return ActNorm(features=config['num_features'])\n",
    "    elif(transform == 'batchNorm'):\n",
    "        return BatchNorm(features=config['num_features'])\n",
    "    else:\n",
    "        print(\"Transform \"+ transform +\" is not supported\")\n",
    "\n",
    "\n",
    "def getFlow(config):\n",
    "    modelName = config['model']\n",
    "    base_dist = StandardNormal(shape=[config['num_features']])\n",
    "    if(not isinstance(modelName,list)):\n",
    "        if(modelName=='simpleRNVP'):\n",
    "            flow = realnvp.SimpleRealNVP(\n",
    "                    features = config['num_features'], \n",
    "                    hidden_features = config['hidden_features'], \n",
    "                    num_layers = config['num_layers'], \n",
    "                    num_blocks_per_layer = config['num_blocks_per_layer'],\n",
    "                    activation = config['activation'],\n",
    "                    use_volume_preserving = config['use_volume_preserving'],\n",
    "                    batch_norm_between_layers = config['batch_norm_between_layers'], \n",
    "                    batch_norm_within_layers = config['batch_norm_within_layers'],\n",
    "                    dropout_probability = config['dropout_probability'] )\n",
    "            return flow\n",
    "        elif(modelName == 'made'):\n",
    "            flow = MaskedAutoregressiveFlow(\n",
    "                    features = config['num_features'], \n",
    "                    hidden_features = config['hidden_features'], \n",
    "                    num_layers = config['num_layers'], \n",
    "                    num_blocks_per_layer = config['num_blocks_per_layer'])\n",
    "            return flow\n",
    "    else:\n",
    "        transforms = []\n",
    "        for _ in range(config['num_layers']):\n",
    "            for layer in modelName:\n",
    "                transforms.append(getTransform(layer,config))     \n",
    "    transform = CompositeTransform(transforms)\n",
    "    flow = Flow(transform, base_dist)\n",
    "    return flow\n",
    "\n",
    "def getAllFlows(expPath, exp_name, maxEpoch):\n",
    "    models = []\n",
    "    for i in range(maxEpoch):\n",
    "        currentPath = os.path.join(expPath, exp_name+str(i)+'.ckpt')\n",
    "        currentDicts = torch.load(currentPath)\n",
    "        config = currentDicts['config']\n",
    "        model = getFlow(config)\n",
    "        model.load_state_dict(currentDicts['model_state_dict'])\n",
    "        models.append(model)\n",
    "    return models\n",
    "        \n",
    "def getBatches(model, nImages=10):\n",
    "    model.eval()\n",
    "    shapes, expressions = demo.load_shape_expressions()\n",
    "    index_id, index_sp, index_ep = 184, 184, 184\n",
    "    index_id, index_sp, index_ep = 184, 184, 184\n",
    "    sp = shapes[index_sp].unsqueeze(0)\n",
    "    ep = expressions[index_ep].unsqueeze(0)\n",
    "    theta = torch.Tensor((0,-35,0))\n",
    "    samples = model.sample(nImages)\n",
    "    samples = samples.detach()\n",
    "    batches_out = [demo.runGlo(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in samples]\n",
    "    printGParams(samples.numpy(), \"current Model\")\n",
    "    return batches_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nfFolderPath = '/home/matthias/ETH/Thesis/nFlows/nflows/output'\n",
    "exp_name = 'blooming-universe-33'\n",
    "expPath = os.path.join(nfFolderPath,exp_name)\n",
    "models = getAllFlows(expPath, exp_name, 37)\n",
    "i=0\n",
    "batches_out = getBatches(models[i],10)\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=10\n",
    "batches_out = getBatches(models[i],10)\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=20\n",
    "batches_out = getBatches(models[i],10)\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=30\n",
    "batches_out = getBatches(models[i],10)\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in models:\n",
    "    makeImages(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfFolderPath = '/home/matthias/ETH/Thesis/nFlows/nflows/output'\n",
    "exp_name = 'golden-energy-32'\n",
    "expPath = os.path.join(nfFolderPath,exp_name)\n",
    "cepoch = 5\n",
    "nfPath = os.path.join(expPath, exp_name+str(cepoch)+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowDicts = torch.load(nfPath)\n",
    "print(flowDicts.keys())\n",
    "config = flowDicts['config']\n",
    "print(config)\n",
    "flow = getFlow(config)\n",
    "model = flow\n",
    "model.load_state_dict(flowDicts['model_state_dict'])\n",
    "flowDicts['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGParams(l, name):\n",
    "    print('Mean '+name+':', \"{:.8E}\".format(l.mean(1).mean().astype('float')))\n",
    "    print('Std '+name+':', \"{:.8E}\".format(l.std(1).mean().astype('float')))\n",
    "    print('Norm '+name+':', \"{:.8E}\".format(np.linalg.norm(l, axis=1).mean().astype('float')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGParams(latent.detach().cpu().numpy(),'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "fold = model.sample(10)\n",
    "fold = fold.detach().numpy()\n",
    "\n",
    "exLatent = latent[:10,:256].cpu()\n",
    "pLatent = model._transform(exLatent)\n",
    "exLatent = exLatent.detach().numpy()\n",
    "pLatent = pLatent[0].detach().numpy()\n",
    "\n",
    "plt.hist(exLatent.flatten(),color='b',bins=100, alpha=1,label='x')\n",
    "plt.hist(pLatent.flatten(),color='r',bins=100, alpha=0.7,label='x->z')\n",
    "#plt.hist(fnew,bins=100,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "printGParams(exLatent,'x')\n",
    "printGParams(pLatent,'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# fold = model.sample(n)\n",
    "# fold = fold.detach().numpy()\n",
    "exLatent = latent[:n,:256].cpu()\n",
    "exLatent = exLatent.detach().numpy()\n",
    "#plt.hist(exLatent.flatten(),color='b',bins=100, alpha=1,label='x')\n",
    "#plt.hist(fold.flatten(),color='r',bins=100, alpha=0.5,label='z->x')\n",
    "#plt.hist(pLatent.flatten(),color='r',bins=100, alpha=0.7,label='x->z')\n",
    "fold = np.random.normal(exLatent.mean(1).mean(0), exLatent.std(1).mean(0), size=(100,256))\n",
    "plt.hist([fold.flatten(),exLatent.flatten()], bins=100, alpha=0.7,label=['G','x'], stacked=False, histtype='stepfilled')\n",
    "#plt.hist(fnew,bins=100,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "printGParams(exLatent,'x')\n",
    "printGParams(fold,'x sampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = model.sample(10)\n",
    "fold = fold.detach().numpy()\n",
    "\n",
    "plt.hist(fold.flatten(),color='b',bins=100, alpha=1,label='z->x')\n",
    "#plt.hist(pLatent.flatten(),color='r',bins=100, alpha=0.7,label='x->z')\n",
    "#plt.hist(fnew,bins=100,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = model._distribution.sample(10)\n",
    "fold = fold.detach().numpy()\n",
    "\n",
    "plt.hist(fold.flatten(),color='b',bins=100, alpha=1,label='z')\n",
    "#plt.hist(pLatent.flatten(),color='r',bins=100, alpha=0.7,label='x->z')\n",
    "#plt.hist(fnew,bins=100,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "printGParams(fold,'prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = model.sample(100)\n",
    "z = zs.detach().numpy()\n",
    "print(z.shape)\n",
    "z = z.flatten()\n",
    "\n",
    "shapes, expressions = demo.load_shape_expressions()\n",
    "index_id, index_sp, index_ep = 184, 184, 184\n",
    "sp = shapes[index_sp].unsqueeze(0)\n",
    "ep = expressions[index_ep].unsqueeze(0)\n",
    "theta = torch.Tensor((0,-35,0))\n",
    "\n",
    "\n",
    "z_sampled = (normalizeT(torch.randn(10, 256),dim=1)*1)\n",
    "samples = zs.detach()\n",
    "# normsSampled.append(torch.norm(samples,dim=1).mean().item())\n",
    "# normsSampled.append(torch.norm(samples,dim=1).mean().item())\n",
    "print('Groundtruth',torch.norm(latent[:1000].detach(),dim=1).mean())\n",
    "print('NF Latent sampled', torch.norm(samples,dim=1).mean())\n",
    "norm = 0\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in samples[:10]]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in exLatent[:5]:\n",
    "    plt.plot(i)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NFLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normsSampled = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfFolderPath = '/home/matthias/ETH/Thesis/nFlows/nflows/output'\n",
    "exp_name = 'feasible-fire-18'\n",
    "nfPath = os.path.join(nfFolderPath,exp_name)\n",
    "flowArray = [] \n",
    "i=0\n",
    "while(True):\n",
    "    filename = os.path.join(nfPath, exp_name+str(i)+'.ckpt')\n",
    "    i+=1\n",
    "    if(os.path.isfile(filename)):\n",
    "        file = np.load(filename)\n",
    "        flowArray.append(file)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDicts(dicts):\n",
    "    modelArray = []\n",
    "    for i in dicts:\n",
    "        model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfFolderPath = '/home/matthias/ETH/Thesis/nFlows/nflows'\n",
    "nfCKPT = 'spring-plant-8.ckpt'\n",
    "nfCKPT = 'divine-universe-10.ckpt' \n",
    "filename = 'fallen-cosmos-12'\n",
    "filename = 'dainty-thunder-13'\n",
    "filename = 'denim-voice-15'\n",
    "\n",
    "nfFolderPath = '/home/matthias/ETH/Thesis/nFlows/nflows/output'\n",
    "exp_name = 'feasible-fire-18'\n",
    "exp_name = 'flowing-fire-19'\n",
    "exp_name = 'silver-totem-20'\n",
    "exp_name = 'crimson-bird-21'\n",
    "exp_name = 'solar-yogurt-28'\n",
    "nfPath = os.path.join(nfFolderPath,exp_name)\n",
    "cepoch = 1\n",
    "nfPath = os.path.join(nfPath, exp_name+str(cepoch)+'.ckpt')\n",
    "\n",
    "## load Nf\n",
    "flowDicts = torch.load(nfPath)\n",
    "print(flowDicts.keys())\n",
    "config = flowDicts['config']\n",
    "print(config.keys())\n",
    "nlayers = config['num_layers']\n",
    "hiddenFeatures = config['hidden_features']\n",
    "latentDim = 256\n",
    "prior = MultivariateNormal(torch.zeros(latentDim), torch.eye(latentDim))\n",
    "\n",
    "#prior = TransformedDistribution(Uniform(torch.zeros(latentDim), torch.ones(latentDim)), SigmoidTransform().inv) # Logistic distribution\n",
    "flows = [AffineHalfFlow(dim=latentDim, parity=i%2, nh=hiddenFeatures) for i in range(nlayers)]\n",
    "#norms = [ActNorm(dim=latentDim) for _ in flows]\n",
    "#flows = list(itertools.chain(*zip(norms, flows)))\n",
    "\n",
    "# flows = [Invertible1x1Conv(dim=latentDim) for i in range(nlayers)]\n",
    "# norms = [ActNorm(dim=latentDim) for _ in flows]\n",
    "# couplings = [AffineHalfFlow(dim=latentDim, parity=i%2, nh=hiddenFeatures) for i in range(len(flows))]\n",
    "# flows = list(itertools.chain(*zip(norms, flows, couplings))) # append a coupling layer after each 1x1\n",
    "    \n",
    "    \n",
    "model = NormalizingFlowModel(prior, flows)\n",
    "model.load_state_dict(flowDicts['model_state_dict'])\n",
    "print('Epoch: ',flowDicts['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "p = model.prior.sample([10])#.squeeze()\n",
    "print(p.shape)\n",
    "new, logdet = model.backward(p)\n",
    "fnew = new[-1].detach().numpy()\n",
    "plt.hist(p.detach().numpy().flatten(),color='r',bins=100, alpha=1,label='nflib prior')\n",
    "plt.hist(fnew.flatten(),bins=100,alpha=0.5, color='b', label = 'z->x')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "printGParams(p.detach().numpy(),'nflib prior')\n",
    "printGParams(fnew,'nflib z->x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = model.sample(10)\n",
    "z = zs[-1]\n",
    "zf = z.detach().numpy()\n",
    "z = zf.flatten()\n",
    "#plt.hist(z, color='r',alpha=1,bins=100, label='z->x')\n",
    "plt.hist([z,exLatent.flatten()], bins=100, alpha=0.7,label=['z->x','x'], stacked=False, histtype='stepfilled')\n",
    "#plt.hist([(exLatent+noise.numpy()).flatten(),exLatent.flatten()], bins=100, alpha=0.7,label=['z->x','x'], stacked=False, histtype='stepfilled')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "printGParams(zf,'Sampled')\n",
    "printGParams(exLatent,'Groundtruth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "l = latent[:1000].detach().cpu().numpy().flatten()\n",
    "flow.eval()\n",
    "f = flow._transform(flow.sample(1000))[0].detach().numpy().flatten()\n",
    "plt.hist(l,color='r',bins=100)\n",
    "plt.hist(f,bins=100,alpha=0.5)\n",
    "plt.show()\n",
    "print('Mean latent:', l.mean().astype('float'))\n",
    "print('Mean flow sample:',f.mean().astype('float'))\n",
    "print('Std latent:',l.std().astype('float'))\n",
    "print('Std flow sample:',f.std().astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = model.sample(100)\n",
    "z = zs[-1]\n",
    "z = z.detach().numpy()\n",
    "print(z.shape)\n",
    "z = z.flatten()\n",
    "\n",
    "shapes, expressions = demo.load_shape_expressions()\n",
    "index_id, index_sp, index_ep = 184, 184, 184\n",
    "sp = shapes[index_sp].unsqueeze(0)\n",
    "ep = expressions[index_ep].unsqueeze(0)\n",
    "theta = torch.Tensor((0,-35,0))\n",
    "samples1 = flow.sample(10)\n",
    "samples2 = flow.sample(10)\n",
    "z_sampled = (normalizeT(torch.randn(10, 256),dim=1)*1)\n",
    "samples =samples1/6\n",
    "#samples = normalizeT(samples,dim=1)*3\n",
    "\n",
    "z_sampled = (normalizeT(torch.randn(10, 256),dim=1)*1)\n",
    "print(torch.norm(z_sampled,dim=1).mean())\n",
    "print('Generator Latent: ',torch.norm(samples,dim=1).mean().detach())\n",
    "samples = zs[-1].detach()\n",
    "normsSampled.append(torch.norm(samples,dim=1).mean().item())\n",
    "print('NF Latent sampled', torch.norm(samples,dim=1).mean())\n",
    "norm = 0\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in samples[:10]]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(normsSampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normsSampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non GLO demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_id, index_sp, index_ep = 184, 184, 184\n",
    "\n",
    "shapes, expressions = demo.load_shape_expressions()\n",
    "sp = shapes[index_sp].unsqueeze(0)\n",
    "ep = expressions[index_ep].unsqueeze(0)\n",
    "\n",
    "z = latent_mean[index_id].unsqueeze(0)\n",
    "theta = torch.Tensor((0,-35,0))\n",
    "\n",
    "batch_out = demo.run(z=z, sp=sp, ep=ep, theta=theta)\n",
    "demo.to_image(batch_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running multiple expressions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_indices = list(range(5))\n",
    "batches_out = [demo.run(z=z, sp=sp, ep=expressions[ep_index].unsqueeze(0), theta=theta) for ep_index in ep_indices]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose\n",
    "Pose can be defined as euler axes (degrees) `theta=(pitch, yaw, roll)`. \n",
    "\n",
    "* pitch > 0 $\\rightarrow$ looking up\n",
    "* yaw > 0 $\\rightarrow$ looking left\n",
    "* roll > 0 $\\rightarrow$ rotate clockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.Tensor((-15, -20, 0))\n",
    "\n",
    "batch_out = demo.run(z=z, sp=sp, ep=ep, theta=theta)\n",
    "demo.to_image(batch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_all = [torch.Tensor((0, -t, 0)) for t in \n",
    "             np.arange(0, 46, 15)]\n",
    "\n",
    "batches_out = [demo.run(z=z, sp=sp, ep=ep, theta=t) for t in theta_all]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Control: Identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "VariTex controls identity via a latent code `z`. You can generate variants of this identity by resampling the latent code. Execute the cell below multiple times to see different outcomes.\n",
    "\n",
    "You can change the variable `multiplier` to sample in more/less extreme regions of the learned distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 184\n",
    "multiplier = 1.5\n",
    "n_samples = 5\n",
    "z_list = torch.distributions.Normal(latent_mean[index].clone(), latent_std[index].clone() * multiplier).rsample((n_samples,)) \n",
    "theta = torch.Tensor((0, 0, 0))\n",
    "\n",
    "batches_out = [demo.run(z=z_l.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z_l in z_list]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "Interpolation between two latent codes smoothly transitions from one identity to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutil.np_util import interpolation\n",
    "n_samples = 5\n",
    "indexA, indexB = 313, 184\n",
    "\n",
    "zA, zB = latent_mean[indexA], latent_mean[indexB]\n",
    "z_interpolated = torch.Tensor(interpolation(n_samples, zA.numpy(), zB.numpy()))\n",
    "\n",
    "batches_out = [demo.run(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in z_interpolated]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = latent[:3]\n",
    "print(z.shape)\n",
    "z0, z1 = z[:,::2], z[:,1::2]\n",
    "print(z0.shape)\n",
    "print(z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathNorms = os.getenv(\"OP\")\n",
    "pathNorms = os.path.join(pathNorms, 'norm_snapshots')\n",
    "latentsNF = []\n",
    "for i in range(15):\n",
    "    filename = 'norms_epoch_'+str(i)\n",
    "    file = os.path.join(pathNorms,filename)\n",
    "    latentNF = np.load(file+'.npy')\n",
    "    latentsNF.append(latentNF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    plt.hist(latentsNF[i][:59990].flatten(),bins=100, color='b')\n",
    "    saveName = os.path.join(pathNorms,'hist'+str(i)+'.png')\n",
    "    plt.ylim(0,5000)\n",
    "    plt.xlim(0.5,3.0)\n",
    "    plt.savefig(saveName)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from varitex.ppl_metric import dnnlib_utils\n",
    "\n",
    "sampling = 'end'\n",
    "p = torch.rand(20) * (1 if sampling == 'full' else 0)\n",
    "print(p.unsqueeze(1).unsqueeze(1).shape)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "print(device)\n",
    "\n",
    "vgg16_url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'\n",
    "with dnnlib_utils.open_url(vgg16_url, verbose=1) as f:\n",
    "    f_detector = torch.jit.load(f).eval().to(device)\n",
    "\n",
    "imgEx = batches_out[0][DIK.IMAGE_OUT].to(device)\n",
    "out = f_detector(imgEx,resize_images=False, return_lpips=True)\n",
    "print(out.shape)\n",
    "\n",
    "f_detector.eval()\n",
    "f_detector.\n",
    "\n",
    "def slerp(a, b, t):\n",
    "    a = a / a.norm(dim=-1, keepdim=True)\n",
    "    b = b / b.norm(dim=-1, keepdim=True)\n",
    "    d = (a * b).sum(dim=-1, keepdim=True)\n",
    "    p = t * torch.acos(d)\n",
    "    c = b - d * a\n",
    "    c = c / c.norm(dim=-1, keepdim=True)\n",
    "    d = a * torch.cos(p) + c * torch.sin(p)\n",
    "    d = d / d.norm(dim=-1, keepdim=True)\n",
    "    return d\n",
    "\n",
    "class PPLSampler(torch.nn.Module):\n",
    "    def __init__(self, model='encoder', epsilon= 1e-4, interpolation = 'linear', sampling, crop, vgg16):\n",
    "    def samplePPL():\n",
    "    #StyleGAN takes generator, epsilon, space, sampling = end/full crop, vgg\n",
    "    # 1. Randomly choose latents and interpolations\n",
    "    if(model=='encoder'):\n",
    "        \n",
    "    elif(model=='GLO'):\n",
    "        \n",
    "    else:\n",
    "        #model with NF\n",
    "    # 2. Interpolate\n",
    "    if(interpolation=='linear'):\n",
    "        \n",
    "    else: \n",
    "    # 3. Generate images\n",
    "    \n",
    "    # 4 Calc Lpips and distance\n",
    "    lpips_t0, lpips_t1 = self.vgg16(img, resize_images=False, return_lpips=True).chunk(2)\n",
    "    dist = (lpips_t0 - lpips_t1).square().sum(1) / self.epsilon ** 2\n",
    "    \n",
    "    \n",
    "    \n",
    "def computePPL()\n",
    "\n",
    "\n",
    "_feature_detector_cache = dict()\n",
    "def get_feature_detector(url, device=torch.device('cpu'), num_gpus=1, rank=0, verbose=False):\n",
    "    assert 0 <= rank < num_gpus\n",
    "    key = (url, device)\n",
    "    if key not in _feature_detector_cache:\n",
    "        is_leader = (rank == 0)\n",
    "        if not is_leader and num_gpus > 1:\n",
    "            torch.distributed.barrier() # leader goes first\n",
    "        with dnnlib.util.open_url(url, verbose=(verbose and is_leader)) as f:\n",
    "            _feature_detector_cache[key] = torch.jit.load(f).eval().to(device)\n",
    "        if is_leader and num_gpus > 1:\n",
    "            torch.distributed.barrier() # others follow\n",
    "    return _feature_detector_cache[key]\n",
    "\n",
    "print(torch.randn([3 * 2, 256], device=device).chunk(2)[0].shape)\n",
    "\n",
    "\n",
    "# Calculate FIDs\n",
    "\n",
    "## Standard (Training)\n",
    "\n",
    "## Interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "opt.update({\"dataset\": 'FFHQ',\n",
    "            \"dataroot_npy\": os.path.join(os.getenv(\"DP\"), 'FFHQ/preprocessed_dataset_new'),\n",
    "            \"image_folder\": os.path.join(os.getenv(\"DP\"), 'FFHQ/images'),\n",
    "            \"transform_mode\": 'all',\n",
    "            \"image_h\": 128,\n",
    "            \"image_w\": 128,\n",
    "            \"batch_size\": 7,\n",
    "            \"num_workers\": 12,\n",
    "            \"semantic_regions\": list(range(1, 16)),\n",
    "            \"keep_background\": False,\n",
    "            \"bg_color\" : 'black',\n",
    "            \"latent_dim\": 256\n",
    "                        })\n",
    "opt_new = ObjectDict(opt)\n",
    "\n",
    "from varitex.data.npy_dataset import NPYDataset\n",
    "train_dataset = NPYDataset(opt_new, split=\"train\", augmentation=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=opt_new.batch_size, num_workers=opt_new.num_workers,\n",
    "                                      shuffle=False, drop_last=True)\n",
    "\n",
    "ckptFolder ='/home/matthias/ETH/Thesis/VariTexLocal/output/ckpts/Res128_GLO_NoNorm'\n",
    "filename = 'epoch=43-step=377079.ckpt'\n",
    "Res128_nonorm_path = os.path.join(ckptFolder, filename)\n",
    "Z = np.load(Res128_nonorm_path)\n",
    "for batch in train_dataloader:\n",
    "    print(batch.keys())\n",
    "    print(batch[DIK.IMAGE_IN].shape)\n",
    "    imgT = batch[DIK.IMAGE_IN]\n",
    "    #imgT = [k for k in imgT]\n",
    "    demo.visualizer_complete.tensor2image(imgT[0].squeeze(), return_format='pil')\n",
    "    break\n",
    "demo.visualizer_complete.tensor2image(imgT[0].squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = batch[DIK.COEFF_SHAPE][0].unsqueeze(0)\n",
    "ep = batch[DIK.COEFF_EXPRESSION][0].unsqueeze(0)\n",
    "# shapes, expressions = demo.load_shape_expressions()\n",
    "# index_id, index_sp, index_ep = 184, 184, 184\n",
    "# sp = shapes[index_sp].unsqueeze(0)\n",
    "# ep = expressions[index_ep].unsqueeze(0)\n",
    "theta = torch.Tensor((0,-100,0))\n",
    "Z = demo.pipeline.Z.weight\n",
    "Z = Z[:59990]\n",
    "batches_out = [demo.runGlo(z=z.unsqueeze(0), sp=sp, ep=ep, theta=theta) for z in Z[:10]]\n",
    "demo.to_image(batches_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "\n",
    "data = train_dataset.data[\"images\"][0]\n",
    "data  = np.array(data).astype('int')\n",
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names=['default', 'norm', 'nonorm', 'nf_glo_alternate', 'nf_glo_joint']\n",
    "def getModel(modelName, opt):\n",
    "    mp_path = '/cluster/project/infk/hilliges/koenigma/Final_Models'\n",
    "    mp_path = '/home/matthias/ETH/Thesis/Final_Models'\n",
    "    if (modelName == 'default'):\n",
    "        folder = os.path.join(mp_path, 'default/checkpoints')\n",
    "        opt.update({\"checkpoint\": os.path.join(folder, 'epoch=43-step=377079.ckpt'),\n",
    "                    \"use_glo\": False,\n",
    "                    \"use_NF\": False,\n",
    "                    \"alternate\": False,\n",
    "                    \"experiment_name\": \"eval_Default\"})\n",
    "    elif (modelName == 'norm'):\n",
    "        folder = os.path.join(mp_path, 'GLO_Norm/checkpoints')\n",
    "        opt.update({\"checkpoint\": os.path.join(folder, 'epoch=43-step=377079.ckpt'),\n",
    "                    \"use_glo\": True,\n",
    "                    \"use_NF\": False,\n",
    "                    \"alternate\": False,\n",
    "                    \"experiment_name\": \"eval_norm\"})\n",
    "    elif (modelName == 'nonorm'):\n",
    "        folder = os.path.join(mp_path, 'GLO_NoNorm/checkpoints')\n",
    "        opt.update({\"checkpoint\": os.path.join(folder, 'epoch=43-step=377079.ckpt'),\n",
    "                    \"use_glo\": True,\n",
    "                    \"use_NF\": False,\n",
    "                    \"alternate\": False,\n",
    "                    \"experiment_name\": \"eval_nonorm\"})\n",
    "    elif (modelName == 'nf_glo_alternate'):\n",
    "        folder = os.path.join(mp_path, 'GLO_NF_ALTERNATE')\n",
    "        opt.update({\"checkpoint\": os.path.join(folder, 'epoch=35-step=308519.ckpt'),\n",
    "                    \"use_glo\": True,\n",
    "                    \"use_NF\": True,\n",
    "                    \"alternate\": True,\n",
    "                    \"experiment_name\": \"eval_nf_glo_alternate\"})\n",
    "    elif (modelName == 'nf_glo_joint'):\n",
    "        folder = os.path.join(mp_path, 'GLO_NF_joint/Res128_GLO_NF_lambdae-3')\n",
    "        opt.update({\"checkpoint\": os.path.join(folder, 'epoch=43-step=377079.ckpt'),\n",
    "                    \"use_glo\": True,\n",
    "                    \"use_NF\": True,\n",
    "                    \"alternate\": False,\n",
    "                    \"experiment_name\": \"eval_nf_glo_joint\"})\n",
    "    else:\n",
    "        print('Model not recognized!')\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from varitex.evaluation.inference import inference_ffhq\n",
    "from varitex import validation\n",
    "#def do_validation(model_name, opt):\n",
    "name = 'default'\n",
    "opt.update({\"dataset\": 'FFHQ',\n",
    "        \"dataroot_npy\": os.path.join(os.getenv(\"DP\"), 'FFHQ/preprocessed_dataset_new'),\n",
    "        \"image_folder\": os.path.join(os.getenv(\"DP\"), 'FFHQ/images'),\n",
    "        \"transform_mode\": 'all',\n",
    "        \"image_h\": 128,\n",
    "        \"image_w\": 128,\n",
    "        \"batch_size\": 1,\n",
    "        \"num_workers\": 12,\n",
    "        \"semantic_regions\": list(range(1, 16)),\n",
    "        \"keep_background\": False,\n",
    "        \"bg_color\" : 'black',\n",
    "        \"latent_dim\": 256,\n",
    "        \"texture_dim\" : 128,\n",
    "        \"texture_nc\": 16,\n",
    "        \"nc_feature2image\": 64,\n",
    "        \"feature2image_num_layers\": 5,\n",
    "        \"use_glo\": False,\n",
    "        \"glo_init\":'pca',\n",
    "        \"pca_file\": os.path.join(os.getenv(\"BP\"), 'datasets/pcaLatents.npy'),\n",
    "        \"experiment_name\": 'eval_NoNorm',\n",
    "        \"use_NF\": False,\n",
    "        \"eval\": True})\n",
    "opt = getModel(name,opt)\n",
    "opt_new = ObjectDict(opt)\n",
    "vals = validation.Validation(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def writetoFile(valDict, metric):\n",
    "        path = os.path.dirname(opt_new.checkpoint)\n",
    "        JSON = json.dumps(valDict)\n",
    "        # open file for writing, \"w\"\n",
    "        filename = metric\n",
    "        f = open(os.path.join(path, filename), \"w\")\n",
    "\n",
    "        # write json object to file\n",
    "        f.write(JSON)\n",
    "        \n",
    "def printJSON(jsonPath):\n",
    "    #jsonPath = os.path.join(jsonPath, 'standards.json')\n",
    "    try:\n",
    "        f = open(jsonPath,)        \n",
    "    except IOError:\n",
    "        return 'NaN'\n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "    print(data)\n",
    "    return data['FID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "finalPath = '/home/matthias/ETH/Thesis/Euler/Final_Models'\n",
    "paths.append(os.path.join(finalPath,'default/checkpoints'))\n",
    "paths.append(os.path.join(finalPath,'GLO_Norm/checkpoints'))\n",
    "paths.append(os.path.join(finalPath,'GLO_NoNorm/checkpoints'))\n",
    "paths.append(os.path.join(finalPath,'GLO_NF_joint/Res128_GLO_NF_lambdae-3'))\n",
    "paths.append(os.path.join(finalPath,'GLO_NF_ALTERNATE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidFiles = []\n",
    "fidFiles.append('FID_constant_interpolated_linear_sampling_latent.json')\n",
    "fidFiles.append('FID_constant_interpolated_None_sampling_latent.json')\n",
    "fidFiles.append('FID_sampled_interpolated_linear_sampling_latent.json')\n",
    "fidFiles.append('FID_sampled_interpolated_None_sampling_latent.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidFiles = []\n",
    "fidFiles.append('FID_constant_interpolated_linear_sampling_latent.json')\n",
    "fidFiles.append('FID_constant_interpolated_linear_sampling_sampled.json')\n",
    "fidFiles.append('FID_constant_interpolated_None_sampling_latent.json')\n",
    "fidFiles.append('FID_constant_interpolated_spherical_sampling_latent.json')\n",
    "fidFiles.append('FID_constant_interpolated_spherical_sampling_sampled.json')\n",
    "fidFiles.append('FID_sampled_interpolated_linear_sampling_latent.json')\n",
    "fidFiles.append('FID_sampled_interpolated_linear_sampling_sampled.json')\n",
    "fidFiles.append('FID_sampled_interpolated_None_sampling_latent.json')\n",
    "fidFiles.append('FID_sampled_interpolated_spherical_sampling_latent.json')\n",
    "fidFiles.append('FID_sampled_interpolated_spherical_sampling_sampled.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valShapes = ['constant','sampled']\n",
    "interpolated= ['linear','None','spherical']\n",
    "sampling = ['latent','sampled']\n",
    "s = []\n",
    "for i in valShapes:\n",
    "    for j in interpolated:\n",
    "        for k in sampling:\n",
    "            s.append(i + '-' +j+'-'+k)\n",
    "            \n",
    "s= np.array(s)\n",
    "s = ['constant-linear-latent', 'constant-linear-sampled' 'constant-None-latent', 'constant-spherical-latent'\n",
    " 'constant-spherical-sampled', 'sampled-linear-latent', 'sampled-linear-sampled' 'sampled-None-latent',\n",
    " 'sampled-spherical-latent', 'sampled-spherical-sampled']\n",
    "s = np.array(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "modelFIDS = np.zeros((10,5))\n",
    "i=0\n",
    "j=0\n",
    "for fid in fidFiles:\n",
    "    j=0\n",
    "    for modelPath in paths:\n",
    "        fidVal = printJSON(os.path.join(modelPath, fid))\n",
    "        modelFIDS[i,j] = fidVal\n",
    "        print(modelPath + ' with FID: ' + fid + ' '  + str(fidVal))\n",
    "        j+=1\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFIDS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(3.4521, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableToLatex(arr):\n",
    "    titles = ['constant-linear-latent', 'constant-linear-sampled' 'constant-None-latent', 'constant-spherical-latent'\n",
    " 'constant-spherical-sampled', 'sampled-linear-latent', 'sampled-linear-sampled' 'sampled-None-latent',\n",
    " 'sampled-spherical-latent', 'sampled-spherical-sampled']\n",
    "    \n",
    "    Models = np.array(['Baseline', 'GLO Norm', 'GLO NoNorm', 'Joint', 'Alternate'])\n",
    "    cols, rows = arr.shape\n",
    "    #print(titles)\n",
    "    for i in range(rows):\n",
    "        row = Models[i]\n",
    "        for j in range(cols):\n",
    "            row+=' & ' + str(np.round(arr[j,i],3))\n",
    "        print(row + ' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['constant-linear-latent', 'constant-linear-sampled', 'constant-None-latent', 'constant-spherical-latent',\n",
    " 'constant-spherical-sampled', 'sampled-linear-latent', 'sampled-linear-sampled', 'sampled-None-latent',\n",
    " 'sampled-spherical-latent', 'sampled-spherical-sampled']\n",
    "titles = np.array(titles)\n",
    "print(titles.take((0,1,5,6),0))\n",
    "tableToLatex(modelFIDS.take((0,1,5,6),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titles.shape)\n",
    "print(titles.take((3,4,8,9),0))\n",
    "tableToLatex(modelFIDS.take((3,4,8,9),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelFIDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableToLatex(modelFIDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 'something'\n",
    "if(not(shape ==  None)):\n",
    "    print('True')\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vals.opt.experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = vals.sample()\n",
    "vals.inference_ffhq(opt_new, n=10000)\n",
    "# psnr = np.array(vals.psnr).mean()\n",
    "# ssim = np.array(vals.ssim).mean()\n",
    "# lpips = np.array(vals.lpips).mean()\n",
    "fid_std = vals.fid_std\n",
    "print(fid_std)\n",
    "# print('PSNR: ' + str(psnr), 'SSIM: '+ str(ssim), 'LPIPS: ' + str(lpips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, metric, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psnr, ssim, lpips, vals.fid_std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid  = vals.metric_fid_std.fid.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = do_validation('norm', opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i, batch in enumerate(vals.dataloader):\n",
    "    real = batch[DIK.IMAGE_IN]\n",
    "    demo.visualizer_complete.tensor2image(real[0].squeeze(), return_format='pil')\n",
    "    if(idx==i):\n",
    "        break\n",
    "\n",
    "demo.visualizer_complete.tensor2image(real[1].squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.visualizer_complete.tensor2image(real[0].squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = torch.rand(1).to(vals.device)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(1)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slerp(a, b, t):\n",
    "    a = a / a.norm(dim=-1, keepdim=True)\n",
    "    b = b / b.norm(dim=-1, keepdim=True)\n",
    "    d = (a * b).sum(dim=-1, keepdim=True)\n",
    "    p = t * torch.acos(d)\n",
    "    c = b - d * a\n",
    "    c = c / c.norm(dim=-1, keepdim=True)\n",
    "    d = a * torch.cos(p) + c * torch.sin(p)\n",
    "    d = d / d.norm(dim=-1, keepdim=True)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.visualizer_complete.tensor2image(slerp(real[0],real[1],0.01).squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.visualizer_complete.tensor2image(i[idx].squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.visualizer_complete.tensor2image(o[idx].squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = demo.pipeline.Z.weight\n",
    "print(latent[2376])\n",
    "print(latent[idcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs = torch.randint(0,vals.dataset.N-2, size=(7,))\n",
    "print(idcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.dataloader.dataset[0]\n",
    "vals.dataloader.dataset.get_unsqueezed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clatent = latent[0:7]\n",
    "clatent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatches(idcs):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[DIK.IMAGE_IN].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = vals.getBatch(mode='sampleVal')\n",
    "\n",
    "batch[DIK.STYLE_LATENT]=clatent\n",
    "\n",
    "batch = vals.model.forward(batch, 0)\n",
    "img = batch[DIK.IMAGE_OUT]\n",
    "demo.visualizer_complete.tensor2image(img[2].squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Loaded\n",
      "Loading BFM 2017 into GPU... (this can take a while)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "opt = getOpt()\n",
    "model_names=['default', 'norm', 'nonorm', 'nf_glo_alternate', 'nf_glo_joint']\n",
    "b  = getModel(model_names[0], opt)\n",
    "opt_new = ObjectDict(opt)\n",
    "vals = validation.Validation(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(vals):\n",
    "    #batch= vals.dataloader.dataset[5]\n",
    "    shape = 'constant'\n",
    "    interpolated = 'linear'\n",
    "    sampling = 'sampled'\n",
    "    batch= {}\n",
    "    batch = vals.getShape(batch, mode=shape)\n",
    "    #batch = vals.sample(sampling=sampling, shape=shape)\n",
    "    batch = vals.interpolate(batch, interpolationMode=interpolated, sampling=sampling)\n",
    "    if (len(batch[DIK.STYLE_LATENT].shape)==1):\n",
    "        batch[DIK.STYLE_LATENT] = batch[DIK.STYLE_LATENT].unsqueeze(0)\n",
    "    if(vals.opt.experiment_name=='eval_Default'):\n",
    "        batch = vals.model.forward_latent2image(batch, -1)\n",
    "    else:\n",
    "        batch = vals.model.forward(batch, -1, std_multiplier=1)\n",
    "    fake = batch[DIK.IMAGE_OUT]\n",
    "    #real = batch[DIK.IMAGE_IN]\n",
    "    print(shape +'_'+interpolated+'_'+sampling+'.npy')\n",
    "    return fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant_linear_sampled.npy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7FB9B85F41F0>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = inference(vals)\n",
    "vals.visualizer_complete.tensor2image(t.squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/matthias/mnp.npy',np.array(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matthias/ETH/Thesis/Final_Models/default/checkpoints\n"
     ]
    }
   ],
   "source": [
    "print(os.path.dirname(vals.opt.checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAABLpUlEQVR4nO39aawtXXYYhq1hD1VnvPe+977564ndZLM5mWhJJilStiSbFJRQEhUrsR1HjhRHjm3ZgAMDSRzYBvxDAYIghgNHUOzIluE/SQgrDmzYgpNIkWFKjJ2maVLsVpNs9vwNb7rDOaeq9t5ryI+67/V99973+ptasAAvXBzUrVO1T9Vae695rQ3wdwrwyuffLSP/HYC/o4+NAA4AAARgTw4YwJ88x3x+vsaeXPNdB7z2DlfPPD32266/ee/Nca59XnuRDwxPn+ojJgDeOIArjzufDAA//rv+nsrQxmk8DLv9uToA0d2Tu4tF34fUVO4eH2+Oj3/x//qX45MHlWdf25/8fZhHfS/v/yER/V4e43s11k3OMM/3n/jp39VUp1qrVIhhnAYjRwjHL9/LqcuBrWiKcXlyp2d+9NY749l5TLnrMwI4oLsTYwzcr9ccwy/+u/83AQAAA2AAASAA/W4P6e95Dn6PCHBtUr6P266B3zaVbi5bBvhjf/QPjcME4B5oqNPFfuTITCytSW1ptewWy369zjm380POiTebNgzjo0fMxCnEZVeHw7A/TBcXGBOUKS5XMcQudSAWmYx5mXg0/4/+H39FATJAe7JK6AYPufYK1/DyPKTcyo4+JIRbz97kd0/PXMM43jjjNz4JoCMYh4G6FPvQVNpYYvQAYIdDdFx2uesXgVzPT6eirA7Lfnx0Ssw9YEqxjsOw3w/DKK21KuQIGBNzXq+a2vDokahQv3hMtr/Y/dDnPtnQEsHZ6dn5o/OzEQxgEeC1N17Zrpd33vzEX/2P/9/67CvcfOwXyJWPBJ5i7D0N+zx6PA/7V+GP/w/+aB0GNXNQ6yO0ab+fhtOz9WodY5R9QYDcL0C9NXG3nLqYewTnGDd3Tgh8f3o2TsM4jtM0TlPjjstYiLlfrSjSo3ceN7EYOC7y/uysNWGzbpE5k5lWkwcPHzbE6SDbzVHu++PN8d11/0t/8wtPXweePDm+t9XwUc39efzbV8ALfvLmBL/6eZW1/aF/4Gf65VLGidzGcihS9Ez2pxdS5GOf/vTdl+6K2IPx27UJiEPM0NSRY+5WJ3e7FOKydxFQW2233OdJRPYXaipDk6ZIOhzuT9MUQwghaq3TYYdMOWUCTzFF1KJCVV9anaT1YmhVAqUUl0fdKq/wCWuy5zOom6vhI5QHT6n73QlwbfrD8/+9euwAadE1t9QnKTJc7KZxAuTI3ctv3lkuFrvT3dnDR+Ceuxxzr2YhpZDS6ugod8lMrba+72MMh935/QfvXpyd73Z7B0BHNSViVSPkxWK1WHSiRkQxRgQPiOtVr3Uax0NpMgwDTM1MyUkJYGx8vPhjf/zn/4O//B/Oau41ZfdWSlxjVh9eJX2Gc3wYkXLrsv2Df/9PtCp5kbGjuh92D0+lKIcQYlivt31kCrGJDqXGlM0J3Prlkoly30diBej7br3ZdDnsTs/eeetbDx8+3O0umpuKETEDUEyBue/7rkscg5QaYmYwB+hTCDF6mw7DUEvdD1OrVc1FxSJTH49O7my3RwHh8aPzNJ391f/yt64+PzwHGy9gVh8Yby+SAdfsl6u/fRWuPccf/SM/d/bw8TiNIjXmoCJogIbgiARMQUyRcLPdTlMTM20ac7/oMpHXaaSYU86b4+McWdVUpDWBVh6dnw+7i1pbaw1D7HOnrpE55UTMIo0BQgg5577rur4jQjOdxmHc7w+7vTQtTcwMIkIMZr5ar4Dj4mijk6LoX/v//NKLjb4XyIPnCcUXw4cyxK6txKdD/OGf+wNV2ijjeLFDomBAyDEEQEbAUus0Tg7W9V3fdfvDFHLfxQgc0G3W3TnG9WbTWnXV9eao63Jrcvrw3d041f0O3AywijITEHUp50WXUzawCBhiDCGsjo4SgoHVcbo4P2vT2MTQsbZ6sT+YmalwCBAQmNO67/tV7pe6H0NO/8l/8lfhuyHxeTb2B8Dhi2TArXz/Vk3/6fFP/b2ff+fBIyQr0iLyerWOgOBAQNM4icqsRFIMqz7vhwnc1ut1mwZtJcSUY4opEmIphYkWq1XXJanl/sOH42FPRNvjo67rhmE8DAMA5q6LjCEEBDdzYnPjmJLUEhn2u93jhw/efvAwcAghEDIgpBTBHTyquYsioQ91JwdXR046lmuYvVUTvfntC9TCF8uJ92iKP5cG8ESL+vv/wM9cnJ1JQEos0wRO68WCSnN1Ihyn2kSJaColhLBar3KX7z94+NLJHQ/Ra+EYUwjM6G5m3i+XHELOCUwuzi8e7w9ElLvF0WpZarm4OCfAvu/NLQccxzrVQjEtuhyIGbyZ1nFwt0ePTxUwIBEiMwNCTsnURNXMmighOjqFYIzY5dj10/kOzX7tV77YbrN7biLkGk7el2x4T3bAi5fYPMTv/Znfc7Erh91p6kJeLqP7ol+AmhwmABQzEXUHlQoA3WJx9+6dUuvZbjhZb8SdXPt+wTFmxqm2xXLBMcx64eHi/DAeatOQUkrZpY3jGELIMcacTeXs/MJUOQZwaK2JKbojQiBSUxJzAuZAhGCGl9oGNJHaBBDBwczdnQjDZgkhjqrqEMbxR37kh49fffn/8L/78+8Fg0/hvc/9q7h9kRr6AmI+HbeQeWhpHcvQ4lC61YoVyljNwc1qEwAMgRCig3cpgtSL3T51S+QQwNBQVETqJC2kpAVBaD8Mh/EwHEZ32x4fq8n9B+fRQd0IoaVsh8M4TmrKxOxep6KqiJhi6LocEMvQvLaUk5nXJi6NmCKzI5k5EgUOY6mmhkTooPvJw7RcLXHR333z5Xsfe3mJ+ebLXkPO8+TBrXr5reh9TzIAnqX20/MM8FO/7/dMQyWnVj3HbpGz1rYfLgiZmVVEWuMQEUPuAgCslwsOvFqu4mJVx7HvutVmK+Mg0rouIqGo7Pdjq20oJcWwWK3ddBhHMzf3GAMSm9l+nKTVwIE5lKlEInePgWMMTFRrc7WUMjKZQW3CjoDQ3ABdVWOKtbVWm6h0XUfEBB65Xy7WnLvV9h6lFW6X1979Bfb/VfPzfckAeAELumlzXaPB7//Z33d4dAYJz3c7QNr0SypKiCFEAKil1DKpO8fU932fs5ss1htyI8B3zy5Adb09Ojne5sDL1aqLKK0OU3nnnXdUFJBiikhYDofz/cFDWuYkKhFB1M73g5oiYM5pnErO2Yn6FEotBBAQRLRPyQjBvYm1Kuhubu6Obo4oamrmDki06LOZL9frxdFRlUoxd3336R/9xPj28Bf/rb8kT14fAew5yL06o9+7GvoiGfA8RROeWPAE8Pmf/Sl/fKjo+/Gw2Wx6Yh3KuB8cQNWYKDDFFHO/6LpORdzdAeo07S4uIHQphr7rtsfHXcCjzTIF2u0HIN5PpY0HBwiB1VxrmUrjmJhJpbr5OIxTrcgMgIEopEQACkaI4MYIzMxIkXGqkxj0XTcMpTZpTcDMTN1NzBHJ3Ik4BGLmnDIQA1Nzi31//LHX7r58lA8Rg/6bf/4vXpuR33VN3HRgPO/fW1jQ8xbU1R/+3X/w9+pQSisSoIsxI5XDVA4jE5l5DBEQQgwcYinl9PFjne8UZQdkCoHIRepktQzVM9NZGUVaE0EiEYlMoK5ixCFEJ3AGY8KqQgTb7bbVYqaEGAimUjhE1QbgKSUKgRGX6+XwYASAi/0+hpRyNnNxdwB3RERARAd3d8CUc4yRQ57KJFOtreb7XNfLftX9hf/9vwkA/Cz2b37enPs3/Rlw4wwC0E0CPF0aN30g86cDPDp9PF4ceNETp0xxOttFwO1ms95uQmAD73IXu8WyX9RS1cHMpDVVWS371XqzWizuHh/fO9pEptbKowcPzh4+rkWIMwFps5Q6ohCYa619yirSxUiITNR3XYqhS/nk+M56uQJ3Ao9EAYkpECKDB0YmCswhhBxDTJFTjCkCABOpqZmaaG21tTZryTGlEGixWDrAeD7cf+t+aTIB/ON/5k/zk/io3YbHq0i7JjhvPb528nYhfG0FXCMgARzefhhevwciOeRoLSxWXU4OsDscHLHvcoihSwEQ33jzY91iiW7jNJ09epDBj7ZLdSaZ+q5LXcxAtUyro6MQIrpP1b0RSEPmLsU+BURYdkcp0gE9BkYkjqmViQM0J1F2CwBO4LHrvJVapRVvIgD42iuvPnr8qNSCFClQ16VWKyFWUXAHJFFFkbOLPXPo+ujuMXU6lOli+upvfOnea6+lvHyPqv0LVsCtI7xIC7p62zWqIsAnfvcPwungBkAQAEx0MjFVIgrMq5M1EVtrzQCsHR49SoeDSVt0eblcsrSmoFK2y8V2sw7kPW9OVi8ZcA5QaxlHfszU3NUc3BCBiXOKuctdCK0JAMSuR1+B68X+AK6BsLVGkcFUpCKRqRkH4jDjGYDJ/O5q+ejsDGJUUTWvooxIHFTVp+nx47PtRjh1XRc22yWoR4oP33549zVeAOyvzMjnwTUu9F11oe+iBT3vNz72Ax9H88Qc1n2GmIATUgghEAF4t+gU4OzBQxXtFsvN8Yk1efDw4XjY9ctln1ICZ4YcYpjGnMObb7yxWnV9Dt501THHWMbpwcVwqHU/NABUMERIMa6WCzHzJtJa1y+dsEgr01RLm0oRdxEhcJGaYiy1AXPIS0A2cGRutbnru48eATIj7oexThM4hsAA3tRjiDGn9dFGmpbSYgyx7ygmZ/PS9hcXv/YbX76G6xdT4rti8ruvgJvgALv97u5yk5dLpxBDSgaL3AECM4HZ6aNTkQbIuVus79wBtG985ev73S6lRDRt+0ViJFeQ6c7JOnLsmJY5LUIITObac7dcdat+PbS2O4yOJO6AwAB9lylGNC+lttbMVZkrondL09ZURYSI0M1VzRRQm8N+qodSaLHZT5Oo5tRxiIRw9/j4699+u9UyW8JgWuuICGUYiKKpVJV+3XeLrA602YbcR/iyPIvBpzh5sS70PMX0RTLgKpXg2ft5f+hefhmJQoiRiB3ycoGEh91+f35uIqpKDJhxHC4evP1gv9+tV6sQOCJEHTPnJeli0b+0XgYM60CbwF0IAQAcGKHPOaQETJNINW+t1VojckrROCawSQQAShlBtekiugkwqJYmSGwqbipm4Hpoiq67UkWkb+YYzyY316PtajiMx+s87Zs4DVVCYHCqrdKIyEJITXQaRnJKqxwJeNP/5N/3e//GX/8leaK3+LOWAVzB+00d/wUy4BYWdE33v8rCPvYDH8ehrO+dKELmEI3Wq/XyaDOcn58/PFUzB4hEBN6vV6VZnaZF1yFAsJbRM8Mq55eWi812u0gxE3WRN+t1jvFSY+m6nBPHaG7qXlsFJA6BgK1VZWYAkSYmrVQwIw5MiADexFRV1VSB0NzGaaqiBj61dhjLMB7GWk4Pw/lY96UQd6f7HSEMk3TL1fnFzgCbiIITJyImZkRc9N3q7jF1OUSaSjt/8PBvfeHX5IZhdCv2XmATwIvtgFvtr5lW7WzfrRIFqqXVaovtprl+66tfH/c7AgohcAgxxS4mZ5LDpCoX56ddjMSAuVvldGe1urvd9Dls+5xCSMSE0IWQuy7lnLs+pkRMyKRmLuLMjojmXslDRIRaq7QqQODGHAIzgGMP7q6tmZq4tiaR2MDNvba66bppvZymKad94gtpWmqJDmoGZqjGTAyEiEWaqgYicwCzcSp0cRFrJ5kxsBJ86tOf/M3f/uqtyuFNFF9V6J+H5+caYtduc4DXP/fxPGnX94TMaDmF8TB6E2bebo6QqMs55ewOGODi0eM2jeqQQ4gh9Dlsu+71O5vIsQuwXfbb5SLNujdSzikvlkyUuz71PcdgzCZirRqSaXORuFoZgBMiYWL0xcJKIQ6zYurg1hrEaO5qJtKkiZqZm2pW99paXSxSTDmEHNPZfjyUOtSKPuJsZzE1EXdEcDVbLVLqsqmnlEKIISaIIaT9rrWr6HsB3NSIbuIZZgLcxPXNGxCgvvtw/dpL/XLhRImZAdcnR4ECmFpt6uBm42F/GEY3OZRqU10uF+vlcsFw1KfXjo5fOdmMu/0mxlVOy66LMRJiiKnLGZhjjKnvmZljRCImMqbaGiuELocQRcTBMUZnEnMEoBgZEZnBDGIAVQVSkaCi0lQNEERFRDgwB3YCYATmxOFsKF0pMaQioharmKm6OyAyoamiecqJAWOMAEAIKUVFfe3Vl956+/5NE/VW7OMT0/V5FApw26q5lVxpvQxAq6PNsJvMpFt1MSdQq1WsFHPo+q6KxBCmIqbapdjlTAgpxpPN5t7RwqSu+rRadDEwM4XAIQR3MFDmzIEMnVzdFMEBYE50IEIgclNiAgfK7KZsDoENAN2JGQkRI5ihGaEjgZmgAwDEEAkA3MG9CicOi5R8YT67kkIYmjjAINrAvTYxQA6idjgMSWTRZWuiYw2bVb9aLe8cn33rAdxg8S/Qha7i8KYd8AwLuubZuHrppz77Ric1LxduDk3zolf3i8enVluIkcEJcZim6TC01lqrKcZF15FrBlnH/NIqoXlyX/VdSimlRIjECAhqhq0BFWFAi5AyBkYkVXV3JiLOZgroCIiIDuhK5G4EDEiIQIROAACECGQEbiGAQ62zDzTEAIQKxsIp8qKLjuZgzNBpSKU4Gox1ktAMTERaFfU+J8TMgd1NW7Np8kRdTv1mCe8+uDpxX+wdwme/umUFXCPRzcVFAG6saYOA+0enroRmUsYud4QIhKVWGUtTmaaK4DHmQIRu60V372TzxnaVQ4wEm65fLhYhRWJUaaqkru5gwG7NIbrPPNw4EMdIAERkpuSM8wOpOiJEdmDQBkgAbg6gzc0R3AEBgUQpMGPWWpAAzNCdAiMREoUYk7n30MW0nwoiNXURl85S7h9e7EsTZkYkN1NRZgW13f2HabvaHh+nkL/+W1+7mUVx0+h9LzKA4MpKuVWwIIACvNpbrYNXkUkCh+Vq2eUemcs07B8/mvZ7Qxz3F61VAkK3AL5gP1rkdQqLEBchbPp+uVzmnGMKxOTopVZpDYgwMDC7u0pTaSIiooDEMSovMGRENHMzm5eFOQC4E13WECACss9sBsDMHJGYgZmYABEIgdAdAJFmRx0hITJjjhwYU+Q+cQwxBI4xIJG7u8owTodxVNOmWkstU4kh5FX/2c9+3w083SJH4TZ8Xrv+OzLg5qVPR/yFf/y/d/rbXw5lVEeOAQIOFztVCRYdMK+X0KqU1vcLMUBzJlr23Z3NYtvFVZdz5MzUd5Ejh8hEyMzIbGaE5O5mJipYgTg4gJuZNEEEI8CmpkjkJlIbgrsouGGMoJdObkcEMzdzFQOYg/s6W2PgDq6qqupuAACIiEgIKYbWGhEGphRDTrl3akUCEeKTYQHGcWrSUowxJVBvtfVd/trf/srzEXuJzJt6PNxg7PAetSAKvk5+3ndKgGL1Yp8iu0OpY0yMKY7nj+uhNgBCWi5Wyy4fb/pFH1d93i66RY45UiAKhCEGZrr8dURkAiIk4hApBEVsIhEZgVxxFohgSiGAOxCZKSAAIJjBEwUDAfxJwGteAaZmKm5gZipqKk1mGrj7bB6YqswkmSmSIiULUT3GECqrz6vM0L02J8TU98M0yWGIXRpfjP5nmf6LNaUAN7B/80xisuXdBdr5o4feJMZgDmUYkAJ6bXVEoAruIjH3gWnR5RRjF3jdpVWX1stFH5gRCRHMDMCJIjPHgEhIGDk4kagSKphxSGjuImCKZOAqtRICcAA3IEAHM0N3RwI3x8sJ55dg7oYAiO5mrTUwA3edfUTuCM6Eiqg+z/KZRXFmj4FzjDmpoKiZmTEAuacYU4rD4TDuhuXxdpnhUG4xa6/NYLwyRW7Ce5UBANChRQZtzdWICIBCjLHvgVFUpnE6PX0sTWLql1236LqcQmSKqQsUOqAOiRADMwC0KqqKRApAxIA4e4aliomaO1BorUmrUsuMSndQFQC/nOCql+wecVbbL8+7O5i5gbuburubOTiAO0JTNXN3QABmJiI1m5chAUSiSMhEiSmGEENgDoSO4IiO4IBIzKv1SvYHV/vhH//8Uxb/AuzfpM21Ky8JcKv1fHXof+f/9JcbLsrUEIiJkGAaJzMjQnGchkFbiyktlqvlcrnq02bdrVf9ZtH1KcbEFCjGwDFQYGAEQmJ28NqaqZqZA2BMnHsMXRMprTU1MWhqTb2K6BzJdZ8D6WZmjvONZqYGKmJmZu6Oqmru5mDuZuBIOlOLCBGJ6PLlZpNr1ouIYwiZKRFGZkIkBCRmZkDmEFttLm15tA1dX6fKOf70T/+9cIOx3KqPwrO86CncIgNuXQEMoABWLqb9BbrH9bpNNS+WgP7w7Xd03HHM/fJotVptj4/urPrFcrHJvOzSMsZACIDuwMTMEcAc0AHMHJDUgEMAAORoDgbkKmAOboIIYjR7GUzQ0UERHWf/IwKgwKzWIJi7t6qqAK7mKs0dAF119kmouYqY1KaXWWKqTQgZmUidyYyVHSKHRdSLioGwgDMRABJiYALEaZjAYH201VaN3KbvKKK3Gro3Z/Zz7YDn8bIZDOCf+hf+p2//1jecHnLgMgyEPA4jgUmpMfV93623R9vN5mi1WKSw7TgxLmMITARmpioiGpCJQwgxuZq5h5CQIjG4Gsyh8jnGBogcZnXeZ80eCAnNHcHngLqrAjm4EwV1d1NTNTUzVTdTBXcHUHMzcwRVs1neElkTRgoc5sQUcA8hOpCaB7JAIbMGInBvIkQcYkwxcghm6gCL7Wp3fhFStKQvxv6L4eldz9WCrl7EKS5g6FIy13EYOcRFvzCzo+O7y9Vis112q/UqRTZ1t0k8cBRDQKPACChqosoWUM1AAgciRkQER+SZeyOAqRETIjEHZjJVAHADBzcDIkAAcHQzMDMxcANUIpwVWZ0lrZiqmhlcCpD5PzczA7eZ788rhwjdCJEQaTYMAMAhIDICIqArAHYpdsslEamqqlhrDL5cLEYqP/UTn/8bv/yF56H4xcEAvFUGwBVedNXOHgeH/k7X9a01M+37ngOptJTiertdHh+HWScxZSZ3zykyAgEQzQ4EEFU1ayJuRswcorubNmmNiBGQiJkDz5/MdMmyAJEImRBnOvjMXJCQeGZupobEgAxIPv8YgKm21lRERU3tcpGZg5ubIQIhzg4ivJR1DoiExIjoMFOFQ8oph5QC0axaMZFMdRbI4PiVL/3KTYw//bzVJ3Hz+ltkwE2K6VjafkcpxD7XsUzjhAii3ud+GgaV2ue0yIlz33eJ3FoTQqAuuaM5qAM5iHkMDEBNNXLiEN2BmYAiMyEFDozISMghIoKrU2C3Wau5zAhxAABEDIAEIYNUdzUDIEYDIycOyGyX+T/gOhsHM+Hm90Z3m31zAI4wq1fg81cAswV2uSw45BgRcNF3EIK0VlpBszoMpTUpz6DqBRL4Vqy+VxkAAKmNNS1zD4dhh+6q0kQR8Hy3W0o268D9eLvtmMphxy6Y0rLvAADciBMQOgIgqhmBo5lZi6Gj2CEYckRiIkIEDgkJiTNQxCBgAuBuAjOCTN0dAVXlUvvnAHN+CTLlztSByD0g7mHagwNTBWqmlXBW+dHMAe3SBjR1v8TSzK0AnBBny05U2a22tl6EnLMASGuI1C2XZgLgp9P1Gf0B5MEtMuDmmcqpW1YY0AxC7tpUVc2BuhxDiIGpz5kQ98PorYbAXUQENHMnBAcHVHVRyzE5EiAhECCBOxCCGSGCgQOIFuYAEQErABAzUkRidyNkt6YipgaOrgrMyIFCNJXZI4derSgzAQgFVBEnACBwNlMHNAcgApx/3fyS+/gTQ/qSx83WiZsdhhHMGAGZMWVRMdGcl+4hiNyqg94KL/jqFkv4ph+DrewrqiohgmsIpMY5pr5LKUUkBjMRATcODKZN2lSgTymkzhFmv5cjzCwawZEQEULkOUHz0o02z25pxOSI2oQIKAS/5DsCiAgIiI6IzLOvAABMDcwc3VsDAwcnYogdYFMp5O7EzODgiIToRIQzXM42nEc2B7fZboPA1BRdbZhKDMEAYiezaGxTCTkwh7kzwvNm7c0zz40H4G086ypJ/tJf/L/80V/4I1JKYKocRWqfc9f1XY4i4q0GgOGwb7VmxsjMJtH9JCQHvMJcEZHcPcQUYw65Iw5EZK3NHMFdVBUBfFJE1FrBFWmOAjBywJgIyd0cCcDc1KogoklzsxmlBmYiiOQUHGn+RURECuSOaEiOzGROBuQAVQAd0ZEIENXN3WZ3oYOoukgbp0pEFCMyO2KbalpkxusdKW7l8s/796lpdn0F3LwUAf6xP/kPnZ8NHBgLeGuExCGA2zBNBA6I0zQCWA7BHVybE0fsQqQQKKSAiO7GhESYc8q5C7ljCswBAGJIpuLozEFBTcRF3MxEXAWYAAlREStJc2Z3nLOafTah3d1MawUiJJxLABAdVBDR3ZmDmiI4OcdEpIKoCATI6ojss3XogOqXshndnghnM7NSS4qBpgk4qMpiuzJ3vCExP6wMeEqTm3TTPvIhmrlWc3NzCEQ081oRNzUiJiJABmfmBYdV3+c0h2EIAJmYiGOMaXESUgrkyEQcARFMKARVNQwODlDdmnqrMwEsOLiDMRmpcwiz9TubZwBgiOomJu5M3AMSBpdWEMA5QQhuSm5gRsyqhkROagDgyInASHWYxb04VLWqguBEiESltVlHSrGFGAipW2/iotNSWq1XMfZ+sf/0+hfJgKc/oIkO+x0hXDqPkZiJCUXUTQE0cNLWKDkhbTLf3W6O1oucY4wBwQnQ0ZEwxhRjCGhETEgIzkyOQVoDN9TCAA6mlICYgjQVlQpmjlHAMACJzHk7DEBoiOQUnQx4dvj7XA+F7uAGxAjOxJfWtSGgIoJSJmeQ0nSsorXpWOphqoepDrVNVfSJGCDEWcqMpQJ66rNOiBE4sMp3qirhOTR4rzLgGlyTww5QSgVmbc2MUu7MIDKrO83ilIK0lgiIYhfj8dHxyXq16vsUkDi4iLgHZlXAkMFd1AJcBj1UzH32uICDqKi5AagBGyULrmUQaSolMJEpuCGOqevBgiECYOzwkg1JRTScVUwAIASwOVJDxEjJkV2LEQOgWB3Gw8V+dzGU/TQeSptqnWoba21P1JsQAjNXbehkZrVpWmDM2cTzKi7CnY+9vv3Gt89fsAJerCZ9xw64lQZPPwkgBHPTGEjQkQkZkYjcAEOgJCaowkw5hmWOq8iLLuUUU2REbKamVlpF4tIqxszgzZDVIyUCdQdzQyJ3VlBpzQDAqzmqgUAwqAZeRSISISB6KyOkjokByaQ5oElz1yYIkBiaUwIHRyIXdwR1x+Q6VuUynJdp2O3O759ePN7tzw9DFW3mRc0AimgTjSFExmoKiMz8lOOFnIAIIk9jBZW33z6/hqv3Ds/4gq7CVUo+XQFUmGOQi2bmkRmAUmBzIgBzBzVEDIFTzjmmnLsuppRTZJpd9lNTBFJKY6nVByIymwhpoUhkpjbnQgGCtKatiSqCq4g5mLMKuAgCOLaYEiChm5kSk7miCoCrW63VoBgJuhhlADBMxKmOe6g7Dxcg+8Mw7vb7s/24H4bdWA7TdKhNxRRwUnXAJk1UzC3EGIgis7TmgGQmqtN+wNyJSGAPOf74j33uv/ivvngVUR8ArhPgJv8hAAZ1lRBJyNwxBQJwAjcABCPCzCHnFMBypD5wjHPfgGjmyhpib1rGYT/sTtNy2y/XQMG0jq15K3OIDJAQUVqTVtydEd1NRCgkJEbK7AJmARFizyCUOkB0FZEKAE20tCYqYpNq8zkxyw3Bd8M0ltZUm1qpUpuIahOdmlTRuVZJRFuTqlpqdTAEmBuvNGnuwAhqFsE5BCk19zlvV8t1H9X+wO//ib/21375g6H+dgLAbayqDQqIWpuKzjItEIoDO9SmjBhjiEyp61OIIaQYQoiZmV0196sGcvb4Yn9xSIE7Z0CCtABrLK5lPEwVwByZEcRJxJoYuVQFU0WSGJhD6lKODNgtADJyAkyEptZMTdSb8tCwiTejOo6lDKoylFZbGUpTbaIAaIAhBQ599loDY0ZnAyZx8CLGhIheRVWba4jEKVCZCmBgotR1q+0WOIzjYcXrbrU4/vgr0+Pf+Qd/8rP/6d/82x9MB72dANfI4ABuatOUA0IiooCuDoRuao6XGQSeYgzoOUUOhDw7siISqxnBMNsB7mbS6rhPeFnU6K5IXmsDcjVR9XEcWqumogZTLbMI7VJa5LRdLpUHg6Pm4ikTkTq2cd9aa2LTVKZxPzSo08VUq5tV1bGUORSJzESh7xerro8xishUa21SRcapEE6iarW6GZoDIjMRYZj9FgAGHmPoVwvksFj1YGBDkVYvHuf/9G8+1yP9/gjwPGmOAONYwTFwxAW3qaB7JHSOtTZRI4Qud8vlKgQKISIiARIzEoeYQdRghwjc5+iWusSRASClHHNHiH2z2nSs2sbzqZ7XVvfD0FoptdVaxDGEkFMeIpdS3HXVWpdTUGVmByhlGqfpMBzO90Mp41jbVCY1j0wGaGbuEGNMue/7vs99FwMgNWqImAJXCQhubs1E3GqKgBiYEDEQziEbMCXmkKOIMICa2CgENpVyMZUPg/1nCHDTC/RUDOhUiTEv+4vHj5EgEBFRbTKVYmoxRUIotSQISBADc+BZ0+cQHEPuFtu7r0fCAC10Rxw75C6gXrrAopMKil20alAVHVOPPmRqOVUxB69EgIghRWIOMVDojBK6qM5RL5mmaRh2h2GoIrVpSomQATzHFGPuui4t7+aUAzl7rVW0Fq1tjlKgY+KwzJ0DqhkiMfP85pEA3JHY5zyW2sbDOI5Dt+o7XMJyUe6fvWAGv8AOeIrk67mhV6MHc/nHXCLbr5dqFZGWXWQkU0e3Sy3I/XA4ELTVnbsp5RDTnHYwp7PFkPLmDSzFrSbbU8RgFw4HK1OZWpsmdRjGw1TlfLc72x3O9me1WWRKMaYYMpEaImFKse+XebGF0ENISGGeo+xEDYl2qiK1TKWpKrlH8K5fp9z1XcekJuemfmgqIvuhDIeD6GwGUpUmjmI6h2IAXM1UJVHoIqsKIsYQHBEQU86Ijinm9aIOg/r1FMWbDp8XfHXdDrga07Enx3/wF342cVouu6a1X3RLBCt62JdpOvMncdpSyoJt6Y0QUgqzc9/BCRy95YB1Om9nD5AQ3c+GYXcYH1/sHpxdjFMdWivSSlUHbGpN6qxyLFNcdmm77JeLbrnarLYn682d3KUUY8SG5IwomMGBI3S5zyHUEABAhWMIgYigtarDtJOm1cGb1iZSyiQqtRX3puqI7oBz+pGbmKcYYwo5MCOWUokIAEKOIXC/XLh77JIHBDUAGC921wjwfqXxLTIAnhz8yX/mT16cXuwuzmKMXfQ3XzlZb1a7dx5845sPap1EGpgQMZjOsb6GCCH5HN0AAHeVhkzNFCEE5Daev3t68bW33/36g0f7YTxMYgbNEABMgBiaY0BjCstlzxRjbRXrqu8DYh+hi8g+kivNuZ5IaE6EMVDOXYoxxiDmFDGEwIGbA4LTYn20Pi5hcXj8ThsnOz/TJs1d1FtrUxNwU5uDnxRDmNv7RsIUQgohEDpiIAwxioi0Nk1jKZO1Y3P7rS//zjWEvl9d6JbsaHjCgpRUTLSUhhiSZdyC6thsGgeRFhgtJgIAwJy4Xy2NYmuTts4DuwliQCRrBYczLuNud/7o9Owb9x+/9faDs6Emiqt+aUCFWQ1FrY1jpOCtpH4RFmsjxyLVrYkKGDFzjEwRiTEkCEtsO3IFVyaKsd9u77kDh9ERU14yA8YYYseLux4zKAwxUS0cOaUcAyVVAe1ydlFBJDUMzMy5y32OgRkRUgwAwExm3qZyMK+1DvudMW3unez3Q/2geL+dAFdHMQA/K7kpx7DuYyzNHz968LX9/fNDT0A5MnIozQxSjMTo7uM0Tk3VTFWpVWIACg7ZeF11KgK1tsjhtddffWO1YSAFVAALuaqKYW1VMdTWYs4dOkxDLLlfdKtlt9reCzEDBupWKCNaxdZciquCO2kjO7BNiRG63gG65bpfLNWUUcXPMsXQfLmiQ3ckq9RUZcTWUJe9AGZ0ZMyMDljEFNCALt+CmIkMIDIvlksEBHNNqTIAY6n1jVfvfuvthx8U+c8S4Kpz9dILhCJlmMZiTdgNwC6GcXu0OdqsH+/r4eJwcTGYGVFQk6mUSibN5mRnU3Z3ZgdQSD2tXj0KR3dP7nBEFlHHEEKjpO6DYKm1OcSAzkHEHIimR/VAJpuYF44Wg6EWHN5NcDGzipg7Cp05ulRmJjAXQbdDqU2VvZBiDjGnHJgo4L2OEHpxlLpy4nF/mBSlVmAC82pgKqpaaptaq2K1VXcITHPQIqREhIvlEsxayus7m3E/AMx5dpd4gw/kl35GBlw9doBIQSadDuM0lbzKi3V49WR78tJxmdqjabBWl32qTQlhqp4DQ0xqpgZzVx4CAxRGICk5sndb1B4JGQQoMGMRA4BezUyqsXtTM/RTrxPhKIuFYebchRQBkRFiiIwOgIGZ85qI3NQ5OFZ3yKLmHhZHVvch5ZwSxxyYiXjGEqIjcg6hNY2rVVY0jGCmdb8fpqLggCnOno8GCNoEkdwNiE1kHAYAP+wPCjru9hDJmpSL+/As3t4vXF8BT+Gf+NN/Incdg4qqE+9a20Lk7WZX7Ox0IIrHR9mRW2mlKV36+hnR5/wDIuRZFM5pPWYOI5ITkjSZpv2oTaRSiLlfuyu2vclUawEDxQR5kSjE1IXVcWA2U9ICAAHNKbvWEHuChkyGBhgAUBREBGnlgSj0HBPFLrISOrjNkV8CAGRkNGls4DJVrUi07Luuw6pWRKipIYk7NosxqDkRDOMI4K0UU6vSAmPfr+pQ3t09g3d/zzR4JiBzK/yf/+1f/LP/9P+4KCBh1/etHijydLorY+kWq5NXjxiQAB6f7uhw0EZgMk3Va191DrMDIRFRCIGJGIEokAlRYAQKEdHH5of9+TgMiEQUnHJIMcUU+iWkLYDN9kREcwXX5O6EABQxBcTGc2o6s7sZYURrxAwjMAFK4kjsIWYiJgSfvdJm7q6qMBcuUQwROSIZiqO2FmBo4kQ8582bg5qZWg4hxcyIiKitMmQklFKv4v19+aWf646+Cv/Gn/9LAPD5H/ns+qV1aP1oYBe7MrQjJD50HXgDJlVVA9OxtWgt0V1wE5VkDO5zvh8BXiZecUBiAMeQEDGFGPN6uR7BxSi6eRMhEEhrJgCXOfMNHSFEIzRAdHNAN0MTMARAVwVpoALmBGhuc6wHTSJIxLksjG0u+nAEV1W32Q+uSt65G5pym0DVkeq8Vub7CGd/cEwJXFWQwPNiud5u1cFqvYquDx4TfgF9AMAQh/OLRYzSWIoEt4uLAxjwasUBzC0HGsFdGjBXqRe6XGgzu8w2I2IOIRBdiik1IvSmQMTUKIQUV2biDoBs5iaTWyMkc0QiB4Q5sZP4MoPHHZ4U6wG4ijZRETVzQLS5DGnOXpkTCsEAKRACkCMhMjEqgoiCNzYzd3IwDIAIqOaXCSwzIuasDEYAAKkNXNNmyYQx569+653nIe3DEuAZQDp7eNoWi64PixwZOTOa2jRNecEpBHFPzNh1gUiRmoq50ZPcvxlUncAQkXjupYpzogc4OiIBmRuYMIJTMNTLMCWiAbgaACAQzBmGjmbz2zoA2pPEwqd/BsCI5q5uYSaCNLjMBHJwJ3cHJzAHJ3QzRTdQdZN5beGTPNQ5q5HQa60qjd0IUVuLKVK43Yvz0RPgv/qvf+P73nwFzMaxXx1vAihRmLt4SZ1UHaTeOT5y08N+QG1TKdaxGbiaiDCgOAQiIJq9EzMrcHN4yoqJEMlNVRUQkRO4mZjPmdM2I4xMm82LAGlueOhqiASIT7Pa5mw3V0NiVWuoIVyW0j+pvEM1V7EmbupzPwMRVwdxEnNzVBMzm4tHzH2uOEsh9amfk3lXXdyXy6SsF3jfPhoCAMCj00cx3BWR2OXFgqkIG5goxGQy9n1/fLwOHE/jGaGxTlWyuWqrRNgAANHNYohmynM2OAcEMFM0AEAHx7nnG+LMbVwdGV3VVC9Tc90NYC4YMDdEAgdAvMwznKe/g7nj5eIDB0IUAABzVGeiOY/ILuWAqlSzJ0gW8VZcmqqozG13DABEJBDnlNarRZdTmabUdQYurT1F99PGex/KDngeIMDFvh0f1f35AV+HtOzNqxwGRAiEy+Pt8XbNDol99epLzrzfjVPVmlpEVDM2N3MibE3Q3UEQ2MGAGR2YaCaPiiCCAbqDavUnjngVMVNxNwxzgaPZZWWdwcx80AFntBvM3YhtdiybuWnQ4B6dnlSLuakDSmtq7mpN3d2KWK0yFWtqTbyKmZmotirgLqoBfb2am29aTJEJ1fTHfuQHfvXXv/xU77y6CdpHSYCZsR4ePzozn+onEBxcwDQsuq7vVouu7zpqgojrRfaQTh+fereak8pQpQFwCAazA42YGWch6TBX8ALSZfK/uSM5ACABmjXRWlRqa7WZmTunDLOGAnOJvAOAqbk+LSr1mXU4QmsuJDHGuTIjsJlcFnc4wFxPYzoX1rioNZFmKupNpZmNrZVamzZEIPQQY4phUJ1aXYAPYx3Od+C3YPujJ8DsmLs/gNL5/fuPuxxzrYt1/9Jrr3QYvRUWJbQ2lv00pOVymdJh2Le0wRjNDEFVGhO7gyP4LCKfZG06ALg5uIoigKM7gpoDeKtVpkMptdRiSMSkc10FEgcGsblxvducMW2iruai3kTNHAlKk6Q2c/mYiFxNfbYJ1FTU3a2KqXtp0szFYBIpYqW1Jm1s9fRiZyJ1rviYxjLVpiYOMpayG37tS799FVHfdd+/90qAa0kWDvDGvdU3H+wF+etvv9v16eWj9Z2XXrrz2svl4c5NwL2VaX+xQ8JNSstlv59KVXGYBQWotAYYL6MoAG44J1UgmAoigRlYE3VidkSTplLbOLQyNdEqErolwFz8pRSTzbFoh8vkzbnaa1aB3C41UgcAmGprom5mEAIquOsT5eaymxCgSBORWlsRmYqMpQ7TNE6l1jYXtTFzCAHMTSyGCGAX52dax6f4uWoJvy/wF2TGXRUm33ywB4BS6344vPXOAzQ7efWV/e5QDwPpJLVOh93hYh9yzstFXG3ArJohoqmZtWI+W0kMqChM5K4OlyJ1bhNj6nNLBiAqYjrspmGcORTETP2W2q7VRsRmjoyXbTrADXCuSFUHcxAFAxSVWdd1d2mi5p1jjgGJ0WcLTJuqmYlaFS1NS2tTbUOtY6mlNTFR02ZOxF2XmXmqBobLo21e9r/x//1Cqbfj7X3R4Ltkxl2DqcBbb5+atIvxfH1yQqWA2mKe/Bc7Hcr2eHvY75cArbXi0NzQTN0VxFTcHUyDqk7DnPVHIRggzrybojrUOoGrGMp0qLUBgDqk7SshrxgrOMlcJON+aRQgwmUmIiCYmTpcNiwQNUQHBzVrquZeK8cQzHSO1F+2mDNralV0msqkWppMrZUmU21VDREpJe7yesubzN7dOVC8/+23TG7H1fvlQrevgOfBvO3pgwd7kOmv/+e/9OOf+9xLx5uuDFqmd+8/uLNYPtxdKM7OE2jOAsBmLtIclG3W/hBrYhZVmi2D2bmgTZwArdVi2kx1qg2QmVmadF7RBTlgQq/VHFwNrM0uvrkTt6hWMTFXRwNQB3dXUURQ1bnwgmpBJCaCWQyog3szryJTlao61Tq11lSrNlFVNyTsEn3uM2/+6A++iehf/+pbj95+2GGwZ2foB7bCnrsCnne1AQjA26cCcJHwS/4jP7L1Op7vHh9K3y1lnMYiwEx9P0mtmjrwuRGYziUwKsysxCGmyOGyx4ODmpqDmao0qVMzoBBiSsxMpsPZuwuZKlDD5I7uOrsEAhEAmM5Fws20ijQ3mXn6LBaeVAjP6dKKAMyBQ7i0sQHUvZlVlbHWsbWptkmaqBq4GMYQNpvlJz7zCe6WZ2+9M+xFhzqJEoL6dcfnB6DBd1kB12y8eX11ABXAAIo0Adg5HsYyORSkpjCVqT9MxyFkxoo5wwhzer/pJKocECmGEM01KODssQEzbQpmInWqpXBMi2Uf+yWDRveL3dmjb531MXLqIORGCzABGQMjE6NrE2m1TLU1lSoyZ5yriqipqbmlGHFOL3NnM3Yn5tlR0tSaaBUtIlNtUyttJp5dakcnq2XgXAeBsOgW65j2XfQf+8Hv/8Jv/OZNG/gjs4SfpkdczZCYP59ug/nW/eGNRw/Xi74xC4fTcUqRQohOeO/1l5eb9TiVRfS5QtLN3GDSQkgqTaOqBiSYa/lUpaiDSSkVAdIyU+iYCUWXi7VidHh0fnaxv//QzUKMXb9crNatKgE8qdqcNSep0oZSSmmiYqaIyCEAoiEAkqoUaUE9BEZAB1ADMRPTJlKlzbly6uoAZoaIZNqmsU7WWq2i0zR989vffvvR7qqW+IHzEp9LgGuBhavBer9CmPv374dXXsbQVR33hymn8PJLx29+/LXP/NCndWhf+fLX1ptFT+wiAN5UTVUU+hTVTDQAgLuLmJg00dqqiK6WCwqRyaTWgAjui36pvOZ4v1vu9rvd4TC1/b6Krddr4Kh1qs3UvDYrVcZSpjI1FQRg5hBjCJEDz32CFEHdpNXkwR1mRiQqrTVRnXUxd5ndHkXM3WuV07N9Bn/n3YcXZ+enp6cPz3bX8PM9kQF+4wCe+BrnhK1X7kQmOj09zzGU1oba1ovu1S69/PHX8vbk3W9++e23392m19bLLiiou7lNIrXKVKY+5xR4Tksu6lOZplpbaynG7XaLBKbCFIDYHQht3XEJ91K3XC0WpbSxVNG5N9bsPZsNKxEVBw8xhhgBIMQ454cBwtNmWQZQWq3SyJGZgVDsspWNmKmqXlavoqk2Aww8DAMsl7W1/Th96+13m96i+H8wGvjz6oRvov4p2JOvfuDTn/nib/7mZrG4uNwyjHcjvvPO+eO3Ht45Ov7yF794enp2/2hzb7tGVbRL78pYKqFX0cQkqk21qu+Gw1BKCvzynXu56wFA9bJ9CiGhk4uwWwhMyy13lg3EQMaL4TC0VsvclUCVCEOI5AaAzBQ4IsJceeBmgG4z2wHwObOYkTA86fQhZuJuTG5zZMCRGKepnF/sFN1yiIt8bRuZm7zhg8iAD7B2fu/v+twv/5dfdIBaLpZdzyExMSLd302/8uu/PZXpa492D053xyeHppo5CAkTTrUO00gAKSUTbCpV9GKc9uNoiHdOTu7dvRNimF/IYe7DGokQHdEsxOCAwVy1cSuGFgO6s7rNrk8zIwfHy4AMz7335njkXKDsbg5zPwoTBSIHn3d6u/TrIBJSIKqG4Bpj56JvvfXgbpO0WayPtn2MRdo19vCBsQ/vt339U/il/98XCYBp7tlDKSVwQETWdpjKV7727W8/eFzGw8UwCECXU5BGzIRYVRncGwBzEx3rNJSpmR4dn9w7Oe77HhBFFQDmZh2mEhCA2BHNEQlnt6aKuRmFmBGBmIPI3K7msokTgOscTrmM4riLaGsN5t2GmeYohCOaGpEgOaLHwEw4LxlxX3RRqtSpDPu9gdw5PrkY283Y7/uKBl+DW/aQeS/wqY8dEUBKEFOY08eXiz6EwExN7eH5cHaYLoTe3Q+7qYSAKYUQmGZHEBExq6laQ/Au8XbZf/r1V1++e9LlaG7mPvfHEmmz8g5zUAZs7m+CxBQ4xMtOCSGGNJeIMDHP9dZzk0QzcHUX1anWcSpqRoiRkREiU2AK81Y1TEw8B4Fn/l6axRxjl6vIJDapPT7b8xzf/3AYv4UAHyCb5ed//hcIYdl3XQjrzeaNz3zi6O5xSjGn1K96DiFyQIdS2lAFKEQMgbnPiS9b82AMHJi7xMeb9Sdfe+XN197cbO4Ad4pxsH6y2AyRcO7wB8SA5Mg2+08xeOh47i3GgfOCQgZIYrFoqM2bQBGYhIeqh6nuDofdYTgMQykF3HJMXQophj7HFEOKgZkoINPcQgGr4qHWvFlxTt16sT1axi5BiP/Fr/wqX0HWU23wAyDwKXx3GXCrufGv/x//HQD46d//B9/59re32+XLb7z2+NtvXZyerzfLbtF5jqthsv1QzO/v2vepEHmK3KWw6lI17HMkU2aIoV+uVpvVKnUbYgM5HM4e7wZHoFXfdynkRSetUuisFcUAJuimQIbZvDMDbVOr+2ncT6WU2ppIkaazTxSgipQmh2kstRBi33XLRZ8ix5A5xBygNjnfH+bWcTEENqvmtdTqvuq7fr3yGAxotVo8uhi+8s2vHOw7GH8qAD4MvD9XxNXPf+jP/MPjWw+3R6vXPvnmS6++knM+HKZln8A8L/ouR9PgrYziTSE5InMIoe+7aNaltOoiEqduhQipW5JN07g/Pbv41je//a13Ho6lIndHx8dHm+2qT11Oqy6DI5r6HLwBQnA1r7XMpSJDqeM0lKZNpbg3aWMtl23HGPsuL/t+uVqdbLddToje5RgZ1XxmO8QUY2iipnoxFgi8XK9SDMQLDPHk5O5vf/WXCOTqfPzAXuj3QYCn6PZn1wEDdB3uASikfr0WrV/9W397GqfNZjkNRaiFLnKLanRf3r0Yt68uSAxjDKu+q6p91y37ntMyxs60MJNIc4fVevvaJz+5fuON4WwYS9XD6LUU12kcYbMZ9vvWmrkTEiMjgLqLVDGrrZUmwzRWVXGfWps1ny7GRdctF3m72fRdn/tusdyiVyaOaYE2kSuoqoqbzR7WSWwYp+XrL23u3SWgcrH7xte/9cXf+NLDR/d3j6/157jFdf8RE+AqJa7qXgKQ+83de15qHU8PZ4/3/fF2dfdES+MQOPerFM8fn7P49GB8dDLeXZ0EdqQx55yRQgi5W8YYYiSz5HMCZlpCn+9u7tyrIx8PojaVetgP0EQNYkq8WgH4YSrDcJjKpFJFvYk4grQmTYs054DgiRkBUwxdCqvlYrHoctcvFn3X9ymFeTNhxst4v87qP5OBi/tYa2P4xGc++cqrL5+dnssQX3nltS/82q8OpxVuU//he7oCXjD03S7ox14ftUz3hwQYaKy1Hh6f9rk7Odo+fve+KRRHK9P9oXyfW0AIgWf/SoiJOFLITIjIoophZXW/hJJj4H5hzI7UTUPPWIYKRimlo+WKOFTVqZTaamltLGUYJ583L2lSRZzQAOYUYQ4hptD3ucup77t+0XVdjwgI7BCIUB1oriZxCAANsDQ7P4x3XnvplTff5K5jGj/xqU/9zte/fv7o0VUX9AeLPt4KH8QOmOl/75VPxOP4oJzff/i1aX/QqpNayHl9dNQvF2UqztRK2TZ6d7fbtZeOujj37WBmQmICBgMgROQQlZljJkIicDPiIKKUOjKMWHRqAE5qZK0DSDE0Io2x5m5MWUVdxFRLLU21zhtAEGIIIXGKoUsxhdDFOBfvowgjEIIS1MtERRCB2uRirNx3r77yaiBysX6zOnr91f/Oj/7Qf/Tv/4f04fJ/PkoCzGvwJGd32nXYvXE0fGnnSCd3j3cPHqnKxeNTd1+u1in2h6F+7RsPf+fe8d/zsZdiQMBw2UfDTM2QCDjg3L/MK0IGN0R0MEdDRO46YhYuWps1waquRohzYIsBlkRC1hCF0GOAQIjgzE6XOZ5zvWBgmlPVL3OT6LIxnKqICDgg+qg21TaYcM7jWPIy9t3iaLnuMYE9o/t/VNiH926I3VR4/9Sf/ufaOxdHj/Lm5Kh/+Q5xcKSXX39t+8pLm7snH//cZ17/1JvL9aKp2WH8zdN33zkbiRMxw9w80nROuEIEoODWwEHqeNn63F3nMA0ApsxdR12kLnkOjaGgNnJBFRdB9YDcB+oiL7u46PNyEbscYmSeqQFERJdtLu0yD2yOFKmUWsWUEEvTi7E+PAxH9467HGut4/7QrdcpL//U/+h/gs/i4SOE97QCnkqeq0+AAP/kP/8vEsD/5t/4c+Xupl68rDqlRWaHwNyt+uHh4+EwbDdLQn6w2331nQd3PvVqiKG0ERHddE4nJFMDnxvNA4CaAsXLpGowAjN1DDmFKIbQJipl9lpeJu06OJKDs4i4N1VRQ1VRVRecqzmIAeeEz7mNJaqTuVbRJkLI5rpvcjaUtF188kd/ZHV0NF4cjpabl0/uHPeLj0re3grvwxXxVOV6Son55v/Fn/0X7y5fevXVV7rlcjqfHEO/3ebN+iCN+rR66WSq09lvnn757UffPh/VMSCrmRnIvO8a4JMEaBeROcQ4b3dtMydSs1YAPDAgM8XIgXl2PMwZ7+RzzSThJYdAACZgxMgcmOeK5SZaqpQqpbXWaqnlME3qDuCT2KN9McJXXn353qv3lstV6hfdcnV0fPcf++//I1df+aNdAe8jJnwzPjNrAjMNjvvFoX+8gX7MYbXZQqC3f+drD+4/iikV1aKGgd55+/F/trSf+/T33+tiR1SroIJ5NBVDNoM5L1xEkIBCdGK09mTjZTNXAgeXOYTTanVTeJKmCAAI88YAjoBMZA4e5k0HAgCYWW3NAdVcHarXUsr+cEBAcHuwH84O05jxB3/gM6lb1OqL1N87ubPtulvN3Y9qNbzXrIir7u9rRtl8sEr5Xlzr40PcLkXl0VfeJubXPv7xcRwdYHnnJOd09s1vf+sbZ1+At37fD36sQyBzBTERnbPy5z1IHNQV3APx5dhI3HXgDF5VG6DPqf9MBOhI8GQHBjRAIJy3bxNRNRXVOecREFUVzNtligrUWsYyzR3+Hu/H++f7wvADP/ZDd+7dBaR6cbY9ucP9YvzGl5ngSc3BdQ/oR6ILve8lNU/5a4rwVfPkz/1rf+708dk47Xe73XgxbO5sN3fuAPqv/fW/cfbNd9Z3Nz/1mY997rUTLs1TZg4hRkAyn0UuMgXgTF7nIiGkiABAmby4ipsbEGhzv8zLQoA5Te4yr0JNpLXWmlzu2aAO6m6A6lBESxPRVmpzcCIcD8NvvXv21cdnJ5/95I//zE8uYx/NF91qsVovQv5n/tQ/8aEx/F3gfauhz4ud4ROp8MmXP/76x1771V/+1XZ+OLl7d3m8Pnn5ZLoYPvPpT33Nbf/uu3/rW4+O+vxyDlZLjK5myDQnGwISg88JVX65fZYgAIggEUBAgkCBYjYz0OZuhHBZ+CWKc4mSG86tnQjBXMzcQcyr6VRlLKVKM3BGHsv4ztnuW4/O4vHyUz/w/cvFeoXh+Ohu3+WTk5fe+crXPhJvz4vhfRPgpiPw6mJ0gH/kH/0f/pVf+o/feP1VcN1P0/D4VM7O0mb9u//wzz74f5EcdruL8esPz+Ld1SoFc2MOIHNFNDMhohEIcpjjhsQB3JEIADgEAkAOc9vWOfkK3ZHczIDRxQlBLnNElRANgZlUTd2a6NTqWIq6cQhTmR7v9l9/eN4Avu+zn33t3it90dV6/crRcZfyL/zcH772yvCR2l83B3+vV1+TPwTfaSB79au//B/838/KxZd+/Yvf/PVff+mNV177zKc+9zM/87nX7t7/4m/9e3/h37vwR69AeGmdGYGIV4sFAuaciUNKmUMiQnAEcKR5w1oKAEiRCQGICJ8kYykhmKqZqKqp1FZrLbU1n3eEA2iOVW1osp+m3TBUUUBs0g7D+NX757tJXvvUGz/5cz97cnzS9dtA+Of+pX/hG19//LykEHh2D+EPD+8vInbNDrxpnfkTRvTH/9gvfP8bn3z93iuvvPZG6heL0K8n7SD8+A//8L/1i//+D7z+g6PyW49375ydn17sHp2fj6UMU5HW1OxJzR4AwFxQxoTuSmiETmhgldDwsl2HAePceNgRiJlDoMtW1Tjv4qbgTaTOgwO01s53+689uDgbGhFKK7/yy7/8ybsn/9t/9X/1P/uTf/pbT7D/9GX9Bro/wnXwvoXwVbYz/+mNb+eDH//8Z//s//xfeeervzVO5ZWXX/49f99P/8j3vfnWV77x/T/6eSL4l//Mn3j04PTxxXnPvsipz912texyt1mv5y4lzAERiePck5fc51pXc0BXc3PTud3MnKGuMu8VM+8EaWoylWoAAjiUupvKUMpQamltGMdvPDg9G8VMf/uty04P623YnQtdKXS5Od/xSobgRwLvww64eee1gNzNTI0vfOFvv3736NHvsAEcLZZr5sXqns7fGfyv/8IvAsA/+Yd/8mKYigxVpJltlwZIqyUAgJmFEACQ8DJByAHUdE5ldHB7ulXJJei8Xc1c/KgK5i4OYlpa09nDYbofDu+c7h9clKlOb5/uYd62BmB3fpnxfHXiX+O3H7kM+C55Qc+756Y3/NqafQrHq9Wdl+62VvOi/+wP/djNe9+81z24L6eTXgxlalprK7U2ke16E5jdnNkR0AkJwPDp1oeupghoBu4wb1sl8455TeZnaE2bWlOraqImolVkGKd3T/cP99PF7uzRIFffiJ99frrSsuraW3+E8GFNa7qNP14d3QH+6v/zrwzjIVH8+f/uH3leg7t//g/92Nlo+ybLHFaL5dFqtV2vt6t1zl2MMTAzElF4Us1qOu9j6OY+93d1m3lPqyoqZm5WRZq0plpFDq0dxunxbvfg7OKts/Hh+fmjXXn6kFefFp/wHLgt5PK9cAd9QBY0w3t5lHVAStwOZ+UKwa7Npn/tr/zX/8uf+9Q0hdPBx3reRJrIWNvd7XbR98YBESPJ3AsT8LKgz+d9keaC0ye5iU1UTKuIqo61mlsRuTgcdofxncdnD/f1fLfrE199wmvBvquex/kMXVkcH7k39EMNePPmp4ILrixqu7LG/cbrPf38Z//QDz9+PJw3z4k3y+V6udquN8ebVZdSF1PgEEIg4qeJVnOF2FzyJaqq1kREdKptKFNVqa0NtQ7TdL7fn+6Gh/t6KFW0fuPB7mqs+6kiaDce7Oq/N0XCRwIfGQGeTpOnlsH8YvrkPfOVDT+urvdr7/YnPv+xMwkBfdXnnNLJZn28Wa26ft0vcpcZ2cCfdGuE2R1t4KYuZiI6ljIr+2MtYymPLi7OhulsP7lDnSYn+9Jb53RlXl9F8fw8V+f702v0isbxEWpB8OEJ4Dfm0VUbDa48MQMEhOKAADQXvF+55SoN/tRPvPqtMwdiI84pblb9uu8XOa+6brlc5Dgrpm7qc9UjADSxUuooMkz1bJxKrYdSz3f7x/uximotgfE373+nw+FV6Xerlw2uLAJ/9vijhY9gBVzVka/ySnyyGmYadAjV560KAZ6019AnrMluDPjzP3Tn8cEVKMTgzKayWq77nLeLtIjcBw6I83a2Clhr243lwX48HdvZfo8UVLVWkVYQ7Fvn3xG5V+f1Vf3yatozXHkM+N7g/RoOvycD0ZNPAXCABCBP2sA+Rbc9wcgLivx/7LXtvCU2EAXG9XKZGXLgODsp3Jv5oejZYXq4n4YymXqKAdxDDG9fPKN5XXtIfHa+3+RIfwdMgY+YAP7sUrjKQzNAAQjPcli7csv1pKfnwGfvLTNZCpEIAIObNsNay8VYm7miPxieQdG1WX+Vy8MVLN/Uc26alvDfcAL4jbf1Z982zDvjAtAV7nT1De22d34BfP61Xg2K2pcePLeJ9q1viM/B79Vvr8H3iAt95Hrtd8a9qVMzgvsl34dnbQK8oQW+L0o879dvws05Djd+/eaZvwtkwLVBb9oy8Bzb8qYGcuvn+30AeA6unz7P83jONfjeoX6GD1ig8WK4al7NYM8/fp7WcXMNvffJ4jcObtV54Mb412bD9xr78L1jQTd/4Hk8Aa5cALetjw/Di54+w01++CHH/KjgeygD4FmcPu/8rfrf847fF77e45jXxv/w9H5f8BGzoGvrGq+cwRvnr9prcOP6m5/+wm/htt+CG9/C+x/n71a4+vTXKEFXzr+X45tr6AXHt/7uhzyGv6sp8d/Cfwv/zYX/P29Y7otDp/m8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7FD1B44413D0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = np.load('/home/matthias/mnp.npy')\n",
    "vals.visualizer_complete.tensor2image(torch.from_numpy(files[3]).squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 'sampled'\n",
    "interpolated = 'linear'\n",
    "sampling = 'latent'\n",
    "n = 3\n",
    "fakes = []\n",
    "for i, batch in tqdm(enumerate(vals.dataloader)):\n",
    "    if(not(shape ==  None)):\n",
    "        batch = vals.getShape(batch, mode=shape)\n",
    "        if(not(interpolated ==  None)):\n",
    "            batch = vals.interpolate(batch, interpolationMode=interpolated, sampling=sampling)\n",
    "    if(vals.opt.experiment_name=='eval_Default' and not(interpolated ==  None)):\n",
    "        batch = vals.model.forward_latent2image(batch, 0)\n",
    "    else:\n",
    "        batch = vals.model.forward(batch, i, std_multiplier=0)\n",
    "    fake = batch[DIK.IMAGE_OUT]\n",
    "    real = batch[DIK.IMAGE_IN]\n",
    "    fakes.append(fake)\n",
    "    if(i*vals.opt.batch_size>n):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "vals.visualizer_complete.tensor2image(fakes[idx].squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = inference(vals)\n",
    "vals.visualizer_complete.tensor2image(t.squeeze(), return_format='pil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python VariTex",
   "language": "python",
   "name": "varitex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
