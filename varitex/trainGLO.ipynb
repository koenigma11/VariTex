{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OP=/cluster/project/infk/hilliges/koenigma/VariTex/outputFolder/\n",
      "env: FP=/cluster/project/infk/hilliges/koenigma/VariTex/\n",
      "env: DP=/cluster/work/hilliges/shared/face_datasets/\n",
      "env: CP=/cluster/project/infk/hilliges/koenigma/VariTex/pretrained/ep44.pkt\n"
     ]
    }
   ],
   "source": [
    "%set_env OP=/cluster/project/infk/hilliges/koenigma/VariTex/outputFolder/\n",
    "%set_env FP=/cluster/project/infk/hilliges/koenigma/VariTex/\n",
    "%set_env DP=/cluster/work/hilliges/shared/face_datasets/\n",
    "%set_env CP=/cluster/project/infk/hilliges/koenigma/VariTex/pretrained/ep44.pkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/cluster/project/infk/hilliges/koenigma/VariTex/')\n",
    "\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "try:\n",
    "    from varitex.custom_callbacks.callbacks import ImageLogCallback\n",
    "    from varitex.data.npy_dataset import NPYDataset\n",
    "    from varitex.modules.pipeline import PipelineModule\n",
    "    from varitex.options.train_options import TrainOptions\n",
    "    from mutil.files import copy_src, mkdir\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Have you added VariTex to your pythonpath?\")\n",
    "    print('To fix this error, go to the root path of the repository \".../VariTex/\" \\n '\n",
    "          'and run \\n'\n",
    "          \"export PYTHONPATH=$PYTHONPATH:$(pwd)\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Data\n",
    "2. Initialize Latent Space randomly or with PCA using a subset of the training data |Z| = (|data|, |latentCode|)\n",
    "3. Project to L2 ball\n",
    "    3. Don't forget to push tensors on Cuda and make z var\n",
    "4. For all images in training data\n",
    "    4. Generate Data\n",
    "    4. Calc loss and backprop\n",
    "    4. project Z to l2 ball\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a316ce9735f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# We load from a checkpoint, so let's load the opt as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/project/infk/hilliges/koenigma/VariTex/varitex/options/base_options.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/project/infk/hilliges/koenigma/VariTex/varitex/options/train_options.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, parser)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Learning rate for generator.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Loss term weights:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/project/infk/hilliges/koenigma/VariTex/varitex/options/base_options.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, parser)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         parser.add_argument('--dataroot_npy', default=os.path.join(os.getenv(\"DP\"), 'FFHQ/preprocessed_dataset'),\n\u001b[0m\u001b[1;32m     12\u001b[0m                             help='Path to the folder with the preprocessed datasets. Should contain .npy files \"R\", \"t\", \"s\", \"sp\", \"ep\", \"segmentation\", \"uv\", \"filename\", and a .npz file \"dataset_splits\".')\n\u001b[1;32m     13\u001b[0m         parser.add_argument('--image_folder', default=os.path.join(os.getenv(\"DP\"), 'FFHQ/images'),\n",
      "\u001b[0;32m/cluster/project/infk/hilliges/koenigma/miniconda3/ENTER/envs/varitex/lib/python3.8/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    \"\"\"TODO: Some dataset transformations, GLO uses Resize(64),crop(64), toTensor(), normalize((.5,.5,.5),(.5,.5,.5))\"\"\"\n",
    "    if opt.dataset_split == \"all\":\n",
    "        # The dataset has no splits or we want to use the full dataset.\n",
    "        dataset = NPYDataset(opt, split=\"all\", augmentation=True)\n",
    "        dataloader = DataLoader(dataset, batch_size=opt.batch_size, num_workers=opt.num_workers, shuffle=True)\n",
    "        do_validation = False\n",
    "    else:\n",
    "        # Separate dataloaders for train and validation.\n",
    "        train_dataset, val_dataset = NPYDataset(opt, split=\"train\", augmentation=True), NPYDataset(opt, split=\"val\",\n",
    "                                                                                                   augmentation=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=opt.batch_size, num_workers=opt.num_workers,\n",
    "                                      shuffle=True)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=opt.batch_size, num_workers=opt.num_workers, shuffle=False)\n",
    "        do_validation = True\n",
    "\n",
    "    ## Define some testing parameters\n",
    "    \"\"\"TODO: define other opt file or change it there/make some default params here (plac)\"\"\"\n",
    "    batch_size = 128\n",
    "    epochs = 25 \n",
    "    code_dim = 128 #2x128 = 256 (latent code size for varitex)\n",
    "    lr_z = 10. #Learning rate for the representation space\n",
    "    loss = 'lap_l1' #Laplacian loss (add combination of l2 loss and lap_l1 here at some point)\n",
    "    init = 'pca' #or use 'random' to initialize randomly\n",
    "    n_pca = (64*64*3*2) #Number of samples to be taken for the pca What is the size here? (imgSize^2*|RGB|*2)\n",
    "        #where does the 2 come from here? 64 can't be from image size\n",
    "     \n",
    "        \n",
    "    if init == 'pca':\n",
    "        from sklearn.decomposition import PCA\n",
    "        \n",
    "        # first, take a subset of train set to fit the PCA\n",
    "        X_pca = np.vstack([\n",
    "            X.cpu().numpy().reshape(len(X), -1)\n",
    "            for i, (X, _, _)\n",
    "             in zip(tqdm(range(n_pca // train_loader.batch_size), 'collect data for PCA'), \n",
    "                    train_loader)\n",
    "        ])\n",
    "        print(\"perform PCA...\")\n",
    "        pca = PCA(n_components=code_dim)\n",
    "        pca.fit(X_pca)\n",
    "        # then, initialize latent vectors to the pca projections of the complete dataset\n",
    "        Z = np.empty((len(train_dataloader.dataset), code_dim))\n",
    "        for X, _, idx in tqdm(train_loader, 'pca projection'):\n",
    "            Z[idx] = pca.transform(X.cpu().numpy().reshape(len(X), -1))\n",
    "\n",
    "    elif init == 'random':\n",
    "        Z = np.random.randn(len(train_set), code_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    pipeline = PipelineModule(opt)\n",
    "    gpus = torch.cuda.device_count()\n",
    "    print(\"Using {} GPU\".format(gpus))\n",
    "    print(\"Writing results to {}\".format(opt.path_out))\n",
    "    mkdir(opt.path_out)\n",
    "\n",
    "    if opt.logger == \"wandb\":\n",
    "        wandb.login()\n",
    "        logger = pl.loggers.WandbLogger(save_dir=opt.path_out, name=opt.experiment_name, project=opt.project)\n",
    "        logger.log_hyperparams(opt)\n",
    "        logger.watch(pipeline)\n",
    "    elif opt.logger == \"tensorboard\":\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=opt.path_out, name=opt.experiment_name\n",
    "        )\n",
    "\n",
    "    trainer = pl.Trainer(logger, gpus=gpus, max_epochs=opt.max_epochs, default_root_dir=opt.path_out,\n",
    "                         terminate_on_nan=False,  # Terminate on nan is expensive\n",
    "                         limit_val_batches=0.25, callbacks=[ImageLogCallback(opt), ModelCheckpoint()],\n",
    "                         fast_dev_run=opt.debug,\n",
    "                         resume_from_checkpoint=opt.checkpoint, weights_summary='top')\n",
    "\n",
    "    if not opt.debug:\n",
    "        # We keep a copy of the current source code and opt config\n",
    "        src_path = os.path.dirname(os.path.realpath(__file__))\n",
    "        copy_src(path_from=src_path,\n",
    "                 path_to=opt.path_out)\n",
    "        with open(os.path.join(opt.path_out, \"opt.json\"), 'w') as f:\n",
    "            json.dump(opt.__dict__, f)\n",
    "\n",
    "    if do_validation:\n",
    "        trainer.fit(pipeline, train_dataloader, val_dataloader)\n",
    "    else:\n",
    "        trainer.fit(pipeline, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varitex",
   "language": "python",
   "name": "varitex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
