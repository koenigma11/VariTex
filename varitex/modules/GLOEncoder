#!/usr/bin/env python
# coding: utf-8

# # Implementation of GLO as a replacement for the VariTex Encoder

# ## Imports


import numpy as np
#from PIL import Image  # for use of demos (in env if needed)

import torch
from torch import nn
import torch.nn.functional as fnn
from torch.autograd import Variable
from torch.optim import SGD
from torchvision.datasets import LSUN
from torchvision import transforms
from torch.utils.data import Dataset
from torchvision.utils import make_grid


# ## Classes for GLO implementation

# ### Workflow: 

# 1. Load Data
# 2. Initialize Latent Space randomly or with PCA using a subset of the training data |Z| = (|data|, |latentCode|)
# 3. Project to L2 ball
#     3. Don't forget to push tensors on Cuda and make z var
# 4. For all images in training data
#     4.1 Generate Data
#     4.2 Calc loss and backprop
#     4.3 project Z to l2 ball   



class IndexedDataset(Dataset):
    """ 
    Wraps another dataset to sample from. Returns the sampled indices during iteration.
    In other words, instead of producing (X, y) it produces (X, y, idx)
    """
    def __init__(self, base_dataset):
        self.base = base_dataset

    def __len__(self):
        return len(self.base)

    def __getitem__(self, idx):
        img, label = self.base[idx]
        return (img, label, idx)
    
    
class GLOEncoder(CustomModule):
    def __init__(self, opt, datasetLen):
        super().__init__(opt)
        if opt.init == 'pca':
            # first, take a subset of train set to fit the PCA
            X_pca = np.vstack([
                X.cpu().numpy().reshape(len(X), -1)
                for i, (X, _, _)
                 in zip(tqdm(range(n_pca // train_loader.batch_size), 'collect data for PCA'), 
                        train_loader)
            ])
            print("perform PCA...")
            pca = PCA(n_components=code_dim)
            pca.fit(X_pca)
            # then, initialize latent vectors to the pca projections of the complete dataset
            Z = np.empty((len(train_dataloader.dataset), code_dim))
            for X, _, idx in tqdm(train_loader, 'pca projection'):
                Z[idx] = pca.transform(X.cpu().numpy().reshape(len(X), -1))
            
    def forward(self, batch, batch_idx):
        image = batch[DIK.IMAGE_IN_ENCODE]
        encoded = self.encoder(image)
        batch[DIK.IMAGE_ENCODED] = encoded
        return batch
        
    
    def projectToL2Ball(z):
        """ project the vectors in z onto the l2 unit norm ball"""
        return z / np.maximum(np.sqrt(np.sum(z**2, axis=1))[:, np.newaxis], 1)

    """Build gaussian kernel """
    #Why did they do it themselves? Look into maybe deploying the one form pytorch 
    def build_gauss_kernel(size=5, sigma=1.0, n_channels=1, cuda=False):
        if size % 2 != 1:
            raise ValueError("kernel size must be uneven")
        grid = np.float32(np.mgrid[0:size,0:size].T)
        gaussian = lambda x: np.exp((x - size//2)**2/(-2*sigma**2))**2
        kernel = np.sum(gaussian(grid), axis=2)
        kernel /= np.sum(kernel)
        # repeat same kernel across depth dimension
        kernel = np.tile(kernel, (n_channels, 1, 1))
        # conv weight should be (out_channels, groups/in_channels, h, w), 
        # and since we have depth-separable convolution we want the groups dimension to be 1
        kernel = torch.FloatTensor(kernel[:, None, :, :])
        if cuda:
            kernel = kernel.cuda()
        return Variable(kernel, requires_grad=False)


    def conv_gauss(img, kernel):
        """ convolve img with a gaussian kernel that has been built with build_gauss_kernel """
        n_channels, _, kw, kh = kernel.shape
        img = fnn.pad(img, (kw//2, kh//2, kw//2, kh//2), mode='replicate')
        return fnn.conv2d(img, kernel, groups=n_channels)

    """Build laplacian pyramid"""
    """Per level take difference of current image and gaussian filtered version"""
    """For every next level take the 2x subsample image of the filtered image"""
    def laplacian_pyramid(img, kernel, max_levels=5):
        current = img
        pyr = []

        for level in range(max_levels):
            filtered = conv_gauss(current, kernel)
            diff = current - filtered
            pyr.append(diff)
            current = fnn.avg_pool2d(filtered, 2)

        pyr.append(current)
        return pyr

    """Class for laplacian l1 loss"""
    #k_size is siye of kernel
    #max_level is depth of pyramids
    class LapLoss(nn.Module):
        def __init__(self, max_levels=5, k_size=5, sigma=2.0):
            super(LapLoss, self).__init__()
            self.max_levels = max_levels
            self.k_size = k_size
            self.sigma = sigma
            self._gauss_kernel = None

        def forward(self, input, target):
            if self._gauss_kernel is None or self._gauss_kernel.shape[1] != input.shape[1]:
                self._gauss_kernel = build_gauss_kernel(
                    size=self.k_size, sigma=self.sigma, 
                    n_channels=input.shape[1], cuda=input.is_cuda
                )
            pyr_input  = laplacian_pyramid( input, self._gauss_kernel, self.max_levels)
            pyr_target = laplacian_pyramid(target, self._gauss_kernel, self.max_levels)
            return sum(fnn.l1_loss(a, b) for a, b in zip(pyr_input, pyr_target))
            
def projectToL2Ball(z):
        """ project the vectors in z onto the l2 unit norm ball"""
        return z / np.maximum(np.sqrt(np.sum(z**2, axis=1))[:, np.newaxis], 1)
